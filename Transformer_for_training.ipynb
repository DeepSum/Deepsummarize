{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zbxhyl_zFlWL"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import sentencepiece as spm\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yH5cg5pSIHaZ"
   },
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K_AjGkWXITKA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(608221, 7)\n"
     ]
    }
   ],
   "source": [
    "path1 = os.getenv('HOME') + '/aiffel/Deep_Sum/total/09' # 자신에 맞는 숫자 집어넣기\n",
    "filenames1 = glob.glob(path1 + \"/*.csv\") \n",
    "\n",
    "\n",
    "dfs = []\n",
    "for filename in filenames1:\n",
    "    dfs.append(pd.read_csv(filename))\n",
    "\n",
    "data = pd.concat(dfs, ignore_index=True)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S-rYZhayIe9x"
   },
   "outputs": [],
   "source": [
    "data = data.drop_duplicates(['contents'], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaned_text(text):\n",
    "    a = re.sub(r'\\[', '&& [',text)\n",
    "    a = re.sub(r'\\]', '] &&',a)\n",
    "    a = re.sub(r'&&', '', a )\n",
    "    \n",
    "    # (~~)의 양 옆에 띄어쓰기를 추가\n",
    "    a = re.sub(r'\\(', '&& (',a)\n",
    "    a = re.sub(r'\\)', ') &&',a)\n",
    "    a = re.sub(r'&&', '', a )\n",
    "    \n",
    "    # <~~>의 양옆에 띄어쓰기를 추가\n",
    "    a = re.sub(r'\\<', '&& <',a)\n",
    "    a = re.sub(r'\\>', '> &&',a)\n",
    "    a = re.sub(r'&&', '', a )\n",
    "    \n",
    "    # (~~)부분 삭제\n",
    "    a = re.sub(r'\\([^)]*\\)', '', a )\n",
    "    \n",
    "    # [~~]부분 삭제\n",
    "    a = re.sub(r'\\[[^)]*\\]', '', a )\n",
    "    \n",
    "    # <~~>부분 삭제\n",
    "    \n",
    "    a = re.sub(r'\\<[^)]*\\>', '', a )\n",
    "    \n",
    "    # 해당 패턴에 해당하는 부분 삭제\n",
    "    pattern = '[\\r|\\n|\\n\\n]'\n",
    "    a = re.sub(pattern = pattern, repl= ' ', string = a)\n",
    "    \n",
    "    # 이메일 삭제\n",
    "    a = re.sub('[a-zA-Z0-9_-]+@\\S+.+[a-zA-Z0-9]', '', a)\n",
    "    #a = re.sub('[a-zA-Z0-9_-]+@[a-z]+.+[a-z]+.+[a-z]', '', a)\n",
    "    #a = re.sub('[a-zA-Z0-9_-]+@[a-z]+.[a-z]', '', a)\n",
    "    #a = re.sub('[a-z]+.[a-z]', '', a)\n",
    "    \n",
    "    # 날짜 삭제\n",
    "    # 필요시 만들기\n",
    "    \n",
    "    \n",
    "    # 마침표 뒤에 띄어쓰기\n",
    "    #a = re.sub('\\.', '. ', a) #숫자의 소수점으로 쓰이는 경우도 있기 때문에 토크나이저에게 맡김 \n",
    "    \n",
    "    # 두칸 이상의 띄어쓰기 제거\n",
    "    a = re.sub('  ', ' ', a)\n",
    "    a = re.sub('  ', ' ', a)\n",
    "    a = re.sub('  ', ' ', a)\n",
    "    \n",
    "    # 양 옆에 공백제거 \n",
    "    a = a.strip()\n",
    "    \n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data['cleaned_texts'] = data['contents'].apply(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 15455,
     "status": "ok",
     "timestamp": 1588996050470,
     "user": {
      "displayName": "rohan jagtap",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjFFnpJjw-7WaiTzz7xrkIJjBBwMs5i3OwVVYALIg=s64",
      "userId": "07173842849534370372"
     },
     "user_tz": -330
    },
    "id": "oXtxc-toIc94",
    "outputId": "d39eac33-f967-492d-e6f7-a2331bb638c0",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    이해찬 전 더불어민주당 대표 .© News1 박세연 기자 이해찬 전 더불어민주당 대...\n",
      "1    박재호 더불어민주당 의원. 사진=뉴스1 박재호 더불어민주당 의원. 사진=뉴스1 사회...\n",
      "2    문재인 대통령이 11일 오전 정부세종청사 코로나19 중앙사고수습본부를 격려 방문을 ...\n",
      "3    “태풍이 지나가고 아침저녁으로 신선한 바람 불어보는 가을의 문턱입니다…맑은 가을 하...\n",
      "4    신정원 이재우 기자 = 로버트 에이브럼스 주한미군사령관 겸 한미연합사령관이 북한이 ...\n",
      "Name: cleaned_texts, dtype: object\n",
      "0          이해찬 \"야당, 秋에 억지부려…의료계, 이번만큼은 엄히 다스려야\"\n",
      "1              페북에 성인물 버젓이…여당 박재호 윤리특위 간사 내정 논란\n",
      "2              문대통령 \"사랑한다는 말씀드린다\"에 중수본서 터져나온 박수\n",
      "3                  추미애, 전국 검찰청 직원에 “檢개혁 완수” 이메일\n",
      "4    주한美사령관 \"北, 코로나 막으려 국경서 사살 명령…도발 징후 없어\"(종합)\n",
      "Name: title, dtype: object\n",
      "367367\n"
     ]
    }
   ],
   "source": [
    "document = data['cleaned_texts']\n",
    "summary = data['title']\n",
    "print(document.head())\n",
    "print(summary.head())\n",
    "print(len(document))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0    기사 섹션 분류 안내 기사의 섹션 정보는 해당 언론사의 분류를 따르고 있습니다. 언...\n",
    "1                                               동영상 뉴스\n",
    "2    유신재 박사. 한국해양과학기술원 제공 유신재 박사. 한국해양과학기술원 제공 황현용 ...\n",
    "3    지난 1일 요하네스버그 OR탐보 국제공항에서 승객들의 체온을 측정하고 있다.  김성...\n",
    "4    국내 대표 마스크 제조업체인 ㈜ 강진 아이앤씨가 코로나19로 힘든 시기에 미래의 주...\n",
    "Name: cleaned_texts, dtype: object\n",
    "0    추미애 “윤석열, 사과부터 했어야”…윤, 내일 국감 발언 ‘주목’\n",
    "1            독감 백신 접종 뒤 9명 사망...\"1명은 질식사\"\n",
    "2                                  22일 알림\n",
    "3        남아공 코로나19 재급증 위험…케이프타운 신규확진 42%↑\n",
    "4         ㈜강진 아이앤씨, 임실군에 어린이 마스크 2만5천장 기부\n",
    "Name: title, dtype: object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f8gKyq1gIq4r"
   },
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "95Zv7FIvKbTi"
   },
   "source": [
    "#### Tokenizing the texts into integer tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #sentencepiece에 적용하기 위한 txt파일 생성\n",
    "\n",
    "# with open('document.txt', 'w') as f:\n",
    "#     for sentence in document:\n",
    "#         f.write('{}\\n'.format(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #sentencepiece에 적용하기 위한 txt파일 생성\n",
    "\n",
    "# with open('summary.txt', 'w') as f:\n",
    "#     for sentence in summary:\n",
    "#         f.write('{}\\n'.format(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_tokenizer(txt):\n",
    "#     templates= '--input={} \\\n",
    "#     --pad_id=0 --pad_piece=<PAD> \\\n",
    "#     --bos_id=1 --bos_piece=<BOS> \\\n",
    "#     --eos_id=2 --eos_piece=<EOS> \\\n",
    "#     --unk_id=3 --unk_piece=<UNK> \\\n",
    "#     --model_prefix={} \\\n",
    "#     --vocab_size={} \\\n",
    "#     --character_coverage={} \\\n",
    "#     --model_type={}'\n",
    "    \n",
    "#     train_input_file = txt\n",
    "#     vocab_size = 400000 # vocab 사이즈\n",
    "#     prefix = txt.split('.')[0] + '_spm' # 저장될 tokenizer 모델에 붙는 이름\n",
    "#     pad_id=0 #<pad> token을 0으로 설정\n",
    "#     bos_id=1 #<BOS> token을 1으로 설정\n",
    "#     eos_id=2 #<EOS> token을 2으로 설정\n",
    "#     unk_id=3 #<UNK> token(unknown)을 3으로 설정\n",
    "#     character_coverage = 1.0 # to reduce character set\n",
    "#     model_type ='unigram' # Choose from unigram (default), bpe, char, or word\n",
    "\n",
    "#     cmd = templates.format(train_input_file,\n",
    "#                            prefix,\n",
    "#                            vocab_size,\n",
    "#                            character_coverage,\n",
    "#                            model_type)\n",
    "    \n",
    "#     spm.SentencePieceTrainer.Train(cmd)\n",
    "#     sp = spm.SentencePieceProcessor()\n",
    "#     sp.Load(prefix + '.model')\n",
    "    \n",
    "#     return sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_tokenizer_summary(txt):\n",
    "#     templates= '--input={} \\\n",
    "#     --pad_id=0 --pad_piece=<PAD> \\\n",
    "#     --bos_id=1 --bos_piece=<BOS> \\\n",
    "#     --eos_id=2 --eos_piece=<EOS> \\\n",
    "#     --unk_id=3 --unk_piece=<UNK> \\\n",
    "#     --model_prefix={} \\\n",
    "#     --vocab_size={} \\\n",
    "#     --character_coverage={} \\\n",
    "#     --model_type={}'\n",
    "    \n",
    "#     train_input_file = txt\n",
    "#     vocab_size = 100000 # vocab 사이즈\n",
    "#     prefix = txt.split('.')[0] + '_spm' # 저장될 tokenizer 모델에 붙는 이름\n",
    "#     character_coverage = 1.0 # to reduce character set\n",
    "#     model_type ='unigram' # Choose from unigram (default), bpe, char, or word\n",
    "\n",
    "#     cmd = templates.format(train_input_file,\n",
    "#                            prefix,\n",
    "#                            vocab_size,\n",
    "#                            character_coverage,\n",
    "#                            model_type)\n",
    "    \n",
    "#     spm.SentencePieceTrainer.Train(cmd)\n",
    "#     sp = spm.SentencePieceProcessor()\n",
    "#     sp.Load(prefix + '.model')\n",
    "    \n",
    "#     return sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# document_tokenizer = generate_tokenizer('document.txt')\n",
    "# summary_tokenizer = generate_tokenizer_summary('summary.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_tokenizer = spm.SentencePieceProcessor(model_file='document_spm.model')\n",
    "summary_tokenizer = spm.SentencePieceProcessor(model_file='summary_spm.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_tokenizer.SetEncodeExtraOptions('bos:eos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = []\n",
    "targets = []\n",
    "\n",
    "for i in range(0, len(document)):\n",
    "    src_tokens = document_tokenizer.EncodeAsIds(document[i])\n",
    "    tgt_tokens = summary_tokenizer.EncodeAsIds(summary[i])\n",
    "    \n",
    "    inputs.append(src_tokens)\n",
    "    targets.append(tgt_tokens)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1311,
     "status": "ok",
     "timestamp": 1588996326633,
     "user": {
      "displayName": "rohan jagtap",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjFFnpJjw-7WaiTzz7xrkIJjBBwMs5i3OwVVYALIg=s64",
      "userId": "07173842849534370372"
     },
     "user_tz": -330
    },
    "id": "KoizyBvLKv8h",
    "outputId": "62198745-1a53-41ef-f10c-5c9ca315fbe4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400000, 100000)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_vocab_size = 400000\n",
    "decoder_vocab_size = 100000\n",
    "\n",
    "# vocab_size\n",
    "encoder_vocab_size, decoder_vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mZden_q9_eZr"
   },
   "source": [
    "#### Obtaining insights on lengths for defining maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cVeMilXr-bpC"
   },
   "outputs": [],
   "source": [
    "# maxlen\n",
    "# taking values > and round figured to 75th percentile\n",
    "# at the same time not leaving high variance\n",
    "encoder_maxlen = 400\n",
    "decoder_maxlen = 75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_SWap3YJBk-D"
   },
   "source": [
    "#### Padding/Truncating sequences for identical sequence lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vEyUBeu7ACRt"
   },
   "outputs": [],
   "source": [
    "inputs = tf.keras.preprocessing.sequence.pad_sequences(inputs, maxlen=encoder_maxlen, padding='post', truncating='post')\n",
    "targets = tf.keras.preprocessing.sequence.pad_sequences(targets, maxlen=decoder_maxlen, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wIP0kIIcB8Rm"
   },
   "source": [
    "### Creating dataset pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LzO6l3-AB7hJ"
   },
   "outputs": [],
   "source": [
    "inputs = tf.cast(inputs, dtype=tf.int32)\n",
    "targets = tf.cast(targets, dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "slZ5f4P4DurS"
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 20000\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wI-fV7eABWN6"
   },
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((inputs, targets)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "isN1CpAXLfsl"
   },
   "source": [
    "### Positional Encoding for adding notion of position among words as unlike RNN this is non-directional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Purv7oyhETDZ"
   },
   "outputs": [],
   "source": [
    "def get_angles(position, i, d_model):\n",
    "    angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n",
    "    return position * angle_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "40J2pc2NEXp5"
   },
   "outputs": [],
   "source": [
    "def positional_encoding(position, d_model):\n",
    "    angle_rads = get_angles(\n",
    "        np.arange(position)[:, np.newaxis],\n",
    "        np.arange(d_model)[np.newaxis, :],\n",
    "        d_model\n",
    "    )\n",
    "\n",
    "    # apply sin to even indices in the array; 2i\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "\n",
    "    # apply cos to odd indices in the array; 2i+1\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "\n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "24Pe01DMMWHc"
   },
   "source": [
    "### Masking\n",
    "\n",
    "- Padding mask for masking \"pad\" sequences\n",
    "- Lookahead mask for masking future words from contributing in prediction of current words in self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hN1wVQAdMVYy"
   },
   "outputs": [],
   "source": [
    "def create_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UmjAPLWuMREE"
   },
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(size):\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n8DqUBc4NFOy"
   },
   "source": [
    "### Building the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WfknVF7hNKf7"
   },
   "source": [
    "#### Scaled Dot Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w_B6M9OBNBKB"
   },
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "    matmul_qk = tf.matmul(q, k, transpose_b=True)\n",
    "\n",
    "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "    if mask is not None:\n",
    "        scaled_attention_logits += (mask * -1e9)  \n",
    "\n",
    "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n",
    "\n",
    "    output = tf.matmul(attention_weights, v)\n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rf7_a5uQOfJk"
   },
   "source": [
    "#### Multi-Headed Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iIuFrdXnNZEC"
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.wq = tf.keras.layers.Dense(d_model)\n",
    "        self.wk = tf.keras.layers.Dense(d_model)\n",
    "        self.wv = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "    def split_heads(self, x, batch_size):\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "    \n",
    "    def call(self, v, k, q, mask):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "\n",
    "        q = self.wq(q)\n",
    "        k = self.wk(k)\n",
    "        v = self.wv(v)\n",
    "\n",
    "        q = self.split_heads(q, batch_size)\n",
    "        k = self.split_heads(k, batch_size)\n",
    "        v = self.split_heads(v, batch_size)\n",
    "\n",
    "        scaled_attention, attention_weights = scaled_dot_product_attention(\n",
    "            q, k, v, mask)\n",
    "\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))\n",
    "        output = self.dense(concat_attention)\n",
    "            \n",
    "        return output, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A49tXMVvOkOZ"
   },
   "source": [
    "### Feed Forward Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d9-qoKuTNwKq"
   },
   "outputs": [],
   "source": [
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(dff, activation='relu'),\n",
    "        tf.keras.layers.Dense(d_model)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B2RRmn2bOpW9"
   },
   "source": [
    "#### Fundamental Unit of Transformer encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HNuoJoFWO335"
   },
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "    def call(self, x, training, mask):\n",
    "        attn_output, _ = self.mha(x, x, x, mask)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(x + attn_output)\n",
    "\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        out2 = self.layernorm2(out1 + ffn_output)\n",
    "\n",
    "        return out2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9i6Zh8gnPqdW"
   },
   "source": [
    "#### Fundamental Unit of Transformer decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7CVmvs6dPMRC"
   },
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
    "        self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout3 = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "    \n",
    "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
    "        attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)\n",
    "        attn1 = self.dropout1(attn1, training=training)\n",
    "        out1 = self.layernorm1(attn1 + x)\n",
    "\n",
    "        attn2, attn_weights_block2 = self.mha2(enc_output, enc_output, out1, padding_mask)\n",
    "        attn2 = self.dropout2(attn2, training=training)\n",
    "        out2 = self.layernorm2(attn2 + out1)\n",
    "\n",
    "        ffn_output = self.ffn(out2)\n",
    "        ffn_output = self.dropout3(ffn_output, training=training)\n",
    "        out3 = self.layernorm3(ffn_output + out2)\n",
    "\n",
    "        return out3, attn_weights_block1, attn_weights_block2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6zt5MUc_QNid"
   },
   "source": [
    "#### Encoder consisting of multiple EncoderLayer(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BrbnTwijQJ-h"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, maximum_position_encoding, rate=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, self.d_model)\n",
    "\n",
    "        self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "        \n",
    "    def call(self, x, training, mask):\n",
    "        seq_len = tf.shape(x)[1]\n",
    "\n",
    "        x = self.embedding(x)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        x = self.dropout(x, training=training)\n",
    "    \n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x, training, mask)\n",
    "    \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4N5LrNrvRexg"
   },
   "source": [
    "#### Decoder consisting of multiple DecoderLayer(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UmeqkZrIRbSB"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size, maximum_position_encoding, rate=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
    "\n",
    "        self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        attention_weights = {}\n",
    "\n",
    "        x = self.embedding(x)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
    "\n",
    "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
    "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
    "    \n",
    "        return x, attention_weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lbMNK_bzSHnh"
   },
   "source": [
    "#### Finally, the Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FXHRG-o4R9Mc"
   },
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, target_vocab_size, pe_input, pe_target, rate=0.1):\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        self.encoder = Encoder(num_layers, d_model, num_heads, dff, input_vocab_size, pe_input, rate)\n",
    "\n",
    "        self.decoder = Decoder(num_layers, d_model, num_heads, dff, target_vocab_size, pe_target, rate)\n",
    "\n",
    "        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "    \n",
    "    def call(self, inp, tar, training, enc_padding_mask, look_ahead_mask, dec_padding_mask):\n",
    "        enc_output = self.encoder(inp, training, enc_padding_mask)\n",
    "\n",
    "        dec_output, attention_weights = self.decoder(tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
    "\n",
    "        final_output = self.final_layer(dec_output)\n",
    "\n",
    "        return final_output, attention_weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UndsMPZXTdSr"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lMTZJdIoSbuy"
   },
   "outputs": [],
   "source": [
    "# hyper-params\n",
    "num_layers = 4\n",
    "d_model = 128\n",
    "dff = 512\n",
    "num_heads = 8\n",
    "EPOCHS = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uOGvkYDNTjIj"
   },
   "source": [
    "#### Adam optimizer with custom learning rate scheduling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tfiynCLlTL8C"
   },
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "    \n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DsVdrENTUERY"
   },
   "source": [
    "#### Defining losses and other metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ip1-943kTXXK"
   },
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(d_model)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ktKwyvKtTvF6"
   },
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uW4LA_45T4Aa"
   },
   "outputs": [],
   "source": [
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ze0u6xxXT7dI"
   },
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9XvKy3v6ULnO"
   },
   "source": [
    "#### Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d5-RcxqFUCuk"
   },
   "outputs": [],
   "source": [
    "transformer = Transformer(\n",
    "    num_layers, \n",
    "    d_model, \n",
    "    num_heads, \n",
    "    dff,\n",
    "    encoder_vocab_size, \n",
    "    decoder_vocab_size, \n",
    "    pe_input=encoder_vocab_size, \n",
    "    pe_target=decoder_vocab_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f56BGiVXU_Dk"
   },
   "source": [
    "#### Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FZxHuyZxU5Pa"
   },
   "outputs": [],
   "source": [
    "def create_masks(inp, tar):\n",
    "    enc_padding_mask = create_padding_mask(inp)\n",
    "    dec_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "    dec_target_padding_mask = create_padding_mask(tar)\n",
    "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "  \n",
    "    return enc_padding_mask, combined_mask, dec_padding_mask\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SYIotvaBVI0d"
   },
   "source": [
    "#### Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7786,
     "status": "ok",
     "timestamp": 1588996357748,
     "user": {
      "displayName": "rohan jagtap",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjFFnpJjw-7WaiTzz7xrkIJjBBwMs5i3OwVVYALIg=s64",
      "userId": "07173842849534370372"
     },
     "user_tz": -330
    },
    "id": "tOc1_3c-VGaL",
    "outputId": "eeab15d7-f887-4f37-dfec-c980948f97d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest checkpoint restored!!\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = \"checkpoints\"\n",
    "\n",
    "ckpt = tf.train.Checkpoint(transformer=transformer, optimizer=optimizer)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=50)\n",
    "\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    print ('Latest checkpoint restored!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f664d6ab910>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_path = \"checkpoints\"\n",
    "latest = tf.train.latest_checkpoint(checkpoint_path)\n",
    "ckpt.restore(latest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WfpI0gS4c06c"
   },
   "source": [
    "#### Training steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xmVOMzkrczgl"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, tar):\n",
    "    tar_inp = tar[:, :-1]\n",
    "    tar_real = tar[:, 1:]\n",
    "\n",
    "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions, _ = transformer(\n",
    "            inp, tar_inp, \n",
    "            True, \n",
    "            enc_padding_mask, \n",
    "            combined_mask, \n",
    "            dec_padding_mask\n",
    "        )\n",
    "        loss = loss_function(tar_real, predictions)\n",
    "\n",
    "    gradients = tape.gradient(loss, transformer.trainable_variables)    \n",
    "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
    "\n",
    "    train_loss(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6000532,
     "status": "ok",
     "timestamp": 1589005387811,
     "user": {
      "displayName": "rohan jagtap",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjFFnpJjw-7WaiTzz7xrkIJjBBwMs5i3OwVVYALIg=s64",
      "userId": "07173842849534370372"
     },
     "user_tz": -330
    },
    "id": "xORKpv69dSW5",
    "outputId": "572d3232-3af4-4bd6-ebc7-a151f6ad000d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 5.7349\n",
      "Epoch 1 Batch 258 Loss 5.2625\n",
      "Epoch 1 Batch 516 Loss 5.1298\n",
      "Epoch 1 Batch 774 Loss 5.1052\n",
      "Epoch 1 Batch 1032 Loss 5.0894\n",
      "Epoch 1 Batch 1290 Loss 5.0813\n",
      "Epoch 1 Batch 1548 Loss 5.0757\n",
      "Epoch 1 Batch 1806 Loss 5.0840\n",
      "Epoch 1 Batch 2064 Loss 5.0904\n",
      "Epoch 1 Batch 2322 Loss 5.0954\n",
      "Epoch 1 Batch 2580 Loss 5.0946\n",
      "Epoch 1 Batch 2838 Loss 5.0943\n",
      "Epoch 1 Batch 3096 Loss 5.0864\n",
      "Epoch 1 Batch 3354 Loss 5.0811\n",
      "Epoch 1 Batch 3612 Loss 5.0716\n",
      "Epoch 1 Batch 3870 Loss 5.0639\n",
      "Epoch 1 Batch 4128 Loss 5.0596\n",
      "Epoch 1 Batch 4386 Loss 5.0564\n",
      "Epoch 1 Batch 4644 Loss 5.0507\n",
      "Epoch 1 Batch 4902 Loss 5.0461\n",
      "Epoch 1 Batch 5160 Loss 5.0417\n",
      "Epoch 1 Batch 5418 Loss 5.0353\n",
      "Epoch 1 Batch 5676 Loss 5.0258\n",
      "Saving checkpoint for epoch 1 at checkpoints/ckpt-3\n",
      "Epoch 1 Loss 5.0221\n",
      "Time taken for 1 epoch: 3455.1916058063507 secs\n",
      "\n",
      "Epoch 2 Batch 0 Loss 5.4946\n",
      "Epoch 2 Batch 258 Loss 5.0824\n",
      "Epoch 2 Batch 516 Loss 4.9710\n",
      "Epoch 2 Batch 774 Loss 4.9400\n",
      "Epoch 2 Batch 1032 Loss 4.9242\n",
      "Epoch 2 Batch 1290 Loss 4.9152\n",
      "Epoch 2 Batch 1548 Loss 4.9079\n",
      "Epoch 2 Batch 1806 Loss 4.9216\n",
      "Epoch 2 Batch 2064 Loss 4.9262\n",
      "Epoch 2 Batch 2322 Loss 4.9334\n",
      "Epoch 2 Batch 2580 Loss 4.9349\n",
      "Epoch 2 Batch 2838 Loss 4.9343\n",
      "Epoch 2 Batch 3096 Loss 4.9278\n",
      "Epoch 2 Batch 3354 Loss 4.9258\n",
      "Epoch 2 Batch 3612 Loss 4.9185\n",
      "Epoch 2 Batch 3870 Loss 4.9144\n",
      "Epoch 2 Batch 4128 Loss 4.9109\n",
      "Epoch 2 Batch 4386 Loss 4.9099\n",
      "Epoch 2 Batch 4644 Loss 4.9057\n",
      "Epoch 2 Batch 4902 Loss 4.9031\n",
      "Epoch 2 Batch 5160 Loss 4.8981\n",
      "Epoch 2 Batch 5418 Loss 4.8925\n",
      "Epoch 2 Batch 5676 Loss 4.8833\n",
      "Saving checkpoint for epoch 2 at checkpoints/ckpt-4\n",
      "Epoch 2 Loss 4.8801\n",
      "Time taken for 1 epoch: 3452.415512561798 secs\n",
      "\n",
      "Epoch 3 Batch 0 Loss 5.2995\n",
      "Epoch 3 Batch 258 Loss 5.0302\n",
      "Epoch 3 Batch 516 Loss 4.8812\n",
      "Epoch 3 Batch 774 Loss 4.8402\n",
      "Epoch 3 Batch 1032 Loss 4.8079\n",
      "Epoch 3 Batch 1290 Loss 4.8063\n",
      "Epoch 3 Batch 1548 Loss 4.8026\n",
      "Epoch 3 Batch 1806 Loss 4.8189\n",
      "Epoch 3 Batch 2064 Loss 4.8265\n",
      "Epoch 3 Batch 2322 Loss 4.8327\n",
      "Epoch 3 Batch 2580 Loss 4.8338\n",
      "Epoch 3 Batch 2838 Loss 4.8359\n",
      "Epoch 3 Batch 3096 Loss 4.8291\n",
      "Epoch 3 Batch 3354 Loss 4.8273\n",
      "Epoch 3 Batch 3612 Loss 4.8209\n",
      "Epoch 3 Batch 3870 Loss 4.8165\n",
      "Epoch 3 Batch 4128 Loss 4.8150\n",
      "Epoch 3 Batch 4386 Loss 4.8135\n",
      "Epoch 3 Batch 4644 Loss 4.8110\n",
      "Epoch 3 Batch 4902 Loss 4.8079\n",
      "Epoch 3 Batch 5160 Loss 4.8034\n",
      "Epoch 3 Batch 5418 Loss 4.7980\n",
      "Epoch 3 Batch 5676 Loss 4.7895\n",
      "Saving checkpoint for epoch 3 at checkpoints/ckpt-5\n",
      "Epoch 3 Loss 4.7867\n",
      "Time taken for 1 epoch: 3450.0553777217865 secs\n",
      "\n",
      "Epoch 4 Batch 0 Loss 5.1917\n",
      "Epoch 4 Batch 258 Loss 4.9654\n",
      "Epoch 4 Batch 516 Loss 4.8127\n",
      "Epoch 4 Batch 774 Loss 4.7585\n",
      "Epoch 4 Batch 1032 Loss 4.7248\n",
      "Epoch 4 Batch 1290 Loss 4.7206\n",
      "Epoch 4 Batch 1548 Loss 4.7212\n",
      "Epoch 4 Batch 1806 Loss 4.7366\n",
      "Epoch 4 Batch 2064 Loss 4.7452\n",
      "Epoch 4 Batch 2322 Loss 4.7519\n",
      "Epoch 4 Batch 2580 Loss 4.7549\n",
      "Epoch 4 Batch 2838 Loss 4.7566\n",
      "Epoch 4 Batch 3096 Loss 4.7529\n",
      "Epoch 4 Batch 3354 Loss 4.7520\n",
      "Epoch 4 Batch 3612 Loss 4.7465\n",
      "Epoch 4 Batch 3870 Loss 4.7421\n",
      "Epoch 4 Batch 4128 Loss 4.7406\n",
      "Epoch 4 Batch 4386 Loss 4.7393\n",
      "Epoch 4 Batch 4644 Loss 4.7372\n",
      "Epoch 4 Batch 4902 Loss 4.7341\n",
      "Epoch 4 Batch 5160 Loss 4.7309\n",
      "Epoch 4 Batch 5418 Loss 4.7252\n",
      "Epoch 4 Batch 5676 Loss 4.7188\n",
      "Saving checkpoint for epoch 4 at checkpoints/ckpt-6\n",
      "Epoch 4 Loss 4.7156\n",
      "Time taken for 1 epoch: 3451.080714225769 secs\n",
      "\n",
      "Epoch 5 Batch 0 Loss 5.0917\n",
      "Epoch 5 Batch 258 Loss 4.9052\n",
      "Epoch 5 Batch 516 Loss 4.7473\n",
      "Epoch 5 Batch 774 Loss 4.6896\n",
      "Epoch 5 Batch 1032 Loss 4.6619\n",
      "Epoch 5 Batch 1290 Loss 4.6551\n",
      "Epoch 5 Batch 1548 Loss 4.6529\n",
      "Epoch 5 Batch 1806 Loss 4.6710\n",
      "Epoch 5 Batch 2064 Loss 4.6804\n",
      "Epoch 5 Batch 2322 Loss 4.6867\n",
      "Epoch 5 Batch 2580 Loss 4.6911\n",
      "Epoch 5 Batch 2838 Loss 4.6922\n",
      "Epoch 5 Batch 3096 Loss 4.6896\n",
      "Epoch 5 Batch 3354 Loss 4.6893\n",
      "Epoch 5 Batch 3612 Loss 4.6820\n",
      "Epoch 5 Batch 3870 Loss 4.6793\n",
      "Epoch 5 Batch 4128 Loss 4.6783\n",
      "Epoch 5 Batch 4386 Loss 4.6785\n",
      "Epoch 5 Batch 4644 Loss 4.6753\n",
      "Epoch 5 Batch 4902 Loss 4.6738\n",
      "Epoch 5 Batch 5160 Loss 4.6713\n",
      "Epoch 5 Batch 5418 Loss 4.6663\n",
      "Epoch 5 Batch 5676 Loss 4.6589\n",
      "Saving checkpoint for epoch 5 at checkpoints/ckpt-7\n",
      "Epoch 5 Loss 4.6563\n",
      "Time taken for 1 epoch: 3517.5916674137115 secs\n",
      "\n",
      "Epoch 6 Batch 0 Loss 5.3711\n",
      "Epoch 6 Batch 258 Loss 4.8519\n",
      "Epoch 6 Batch 516 Loss 4.7026\n",
      "Epoch 6 Batch 774 Loss 4.6358\n",
      "Epoch 6 Batch 1032 Loss 4.6020\n",
      "Epoch 6 Batch 1290 Loss 4.6012\n",
      "Epoch 6 Batch 1548 Loss 4.6027\n",
      "Epoch 6 Batch 1806 Loss 4.6201\n",
      "Epoch 6 Batch 2064 Loss 4.6300\n",
      "Epoch 6 Batch 2322 Loss 4.6389\n",
      "Epoch 6 Batch 2580 Loss 4.6391\n",
      "Epoch 6 Batch 2838 Loss 4.6399\n",
      "Epoch 6 Batch 3096 Loss 4.6364\n",
      "Epoch 6 Batch 3354 Loss 4.6359\n",
      "Epoch 6 Batch 3612 Loss 4.6314\n",
      "Epoch 6 Batch 3870 Loss 4.6273\n",
      "Epoch 6 Batch 4128 Loss 4.6287\n",
      "Epoch 6 Batch 4386 Loss 4.6276\n",
      "Epoch 6 Batch 4644 Loss 4.6236\n",
      "Epoch 6 Batch 4902 Loss 4.6226\n",
      "Epoch 6 Batch 5160 Loss 4.6199\n",
      "Epoch 6 Batch 5418 Loss 4.6150\n",
      "Epoch 6 Batch 5676 Loss 4.6084\n",
      "Saving checkpoint for epoch 6 at checkpoints/ckpt-8\n",
      "Epoch 6 Loss 4.6059\n",
      "Time taken for 1 epoch: 3452.677609205246 secs\n",
      "\n",
      "Epoch 7 Batch 0 Loss 5.3247\n",
      "Epoch 7 Batch 258 Loss 4.8276\n",
      "Epoch 7 Batch 516 Loss 4.6452\n",
      "Epoch 7 Batch 774 Loss 4.5931\n",
      "Epoch 7 Batch 1032 Loss 4.5599\n",
      "Epoch 7 Batch 1290 Loss 4.5562\n",
      "Epoch 7 Batch 1548 Loss 4.5577\n",
      "Epoch 7 Batch 1806 Loss 4.5769\n",
      "Epoch 7 Batch 2064 Loss 4.5859\n",
      "Epoch 7 Batch 2322 Loss 4.5931\n",
      "Epoch 7 Batch 2580 Loss 4.5944\n",
      "Epoch 7 Batch 2838 Loss 4.5961\n",
      "Epoch 7 Batch 3096 Loss 4.5928\n",
      "Epoch 7 Batch 3354 Loss 4.5936\n",
      "Epoch 7 Batch 3612 Loss 4.5879\n",
      "Epoch 7 Batch 3870 Loss 4.5837\n",
      "Epoch 7 Batch 4128 Loss 4.5843\n",
      "Epoch 7 Batch 4386 Loss 4.5859\n",
      "Epoch 7 Batch 4644 Loss 4.5835\n",
      "Epoch 7 Batch 4902 Loss 4.5818\n",
      "Epoch 7 Batch 5160 Loss 4.5789\n",
      "Epoch 7 Batch 5418 Loss 4.5755\n",
      "Epoch 7 Batch 5676 Loss 4.5686\n",
      "Saving checkpoint for epoch 7 at checkpoints/ckpt-9\n",
      "Epoch 7 Loss 4.5654\n",
      "Time taken for 1 epoch: 3456.637855529785 secs\n",
      "\n",
      "Epoch 8 Batch 0 Loss 5.1180\n",
      "Epoch 8 Batch 258 Loss 4.7824\n",
      "Epoch 8 Batch 516 Loss 4.6119\n",
      "Epoch 8 Batch 774 Loss 4.5474\n",
      "Epoch 8 Batch 1032 Loss 4.5183\n",
      "Epoch 8 Batch 1290 Loss 4.5184\n",
      "Epoch 8 Batch 1548 Loss 4.5160\n",
      "Epoch 8 Batch 1806 Loss 4.5344\n",
      "Epoch 8 Batch 2064 Loss 4.5460\n",
      "Epoch 8 Batch 2322 Loss 4.5562\n",
      "Epoch 8 Batch 2580 Loss 4.5584\n",
      "Epoch 8 Batch 2838 Loss 4.5602\n",
      "Epoch 8 Batch 3096 Loss 4.5552\n",
      "Epoch 8 Batch 3354 Loss 4.5560\n",
      "Epoch 8 Batch 3612 Loss 4.5503\n",
      "Epoch 8 Batch 3870 Loss 4.5471\n",
      "Epoch 8 Batch 4128 Loss 4.5470\n",
      "Epoch 8 Batch 4386 Loss 4.5472\n",
      "Epoch 8 Batch 4644 Loss 4.5446\n",
      "Epoch 8 Batch 4902 Loss 4.5435\n",
      "Epoch 8 Batch 5160 Loss 4.5411\n",
      "Epoch 8 Batch 5418 Loss 4.5377\n",
      "Epoch 8 Batch 5676 Loss 4.5315\n",
      "Saving checkpoint for epoch 8 at checkpoints/ckpt-10\n",
      "Epoch 8 Loss 4.5287\n",
      "Time taken for 1 epoch: 3451.2081801891327 secs\n",
      "\n",
      "Epoch 9 Batch 0 Loss 5.0814\n",
      "Epoch 9 Batch 258 Loss 4.7445\n",
      "Epoch 9 Batch 516 Loss 4.5815\n",
      "Epoch 9 Batch 774 Loss 4.5184\n",
      "Epoch 9 Batch 1032 Loss 4.4882\n",
      "Epoch 9 Batch 1290 Loss 4.4830\n",
      "Epoch 9 Batch 1548 Loss 4.4834\n",
      "Epoch 9 Batch 1806 Loss 4.5053\n",
      "Epoch 9 Batch 2064 Loss 4.5143\n",
      "Epoch 9 Batch 2322 Loss 4.5231\n",
      "Epoch 9 Batch 2580 Loss 4.5258\n",
      "Epoch 9 Batch 2838 Loss 4.5292\n",
      "Epoch 9 Batch 3096 Loss 4.5243\n",
      "Epoch 9 Batch 3354 Loss 4.5241\n",
      "Epoch 9 Batch 3612 Loss 4.5188\n",
      "Epoch 9 Batch 3870 Loss 4.5165\n",
      "Epoch 9 Batch 4128 Loss 4.5168\n",
      "Epoch 9 Batch 4386 Loss 4.5181\n",
      "Epoch 9 Batch 4644 Loss 4.5152\n",
      "Epoch 9 Batch 4902 Loss 4.5127\n",
      "Epoch 9 Batch 5160 Loss 4.5105\n",
      "Epoch 9 Batch 5418 Loss 4.5077\n",
      "Epoch 9 Batch 5676 Loss 4.5013\n",
      "Saving checkpoint for epoch 9 at checkpoints/ckpt-11\n",
      "Epoch 9 Loss 4.4985\n",
      "Time taken for 1 epoch: 3451.572695493698 secs\n",
      "\n",
      "Epoch 10 Batch 0 Loss 5.0641\n",
      "Epoch 10 Batch 258 Loss 4.7041\n",
      "Epoch 10 Batch 516 Loss 4.5546\n",
      "Epoch 10 Batch 774 Loss 4.4955\n",
      "Epoch 10 Batch 1032 Loss 4.4615\n",
      "Epoch 10 Batch 1290 Loss 4.4580\n",
      "Epoch 10 Batch 1548 Loss 4.4597\n",
      "Epoch 10 Batch 1806 Loss 4.4765\n",
      "Epoch 10 Batch 2064 Loss 4.4854\n",
      "Epoch 10 Batch 2322 Loss 4.4950\n",
      "Epoch 10 Batch 2580 Loss 4.4978\n",
      "Epoch 10 Batch 2838 Loss 4.4999\n",
      "Epoch 10 Batch 3096 Loss 4.4955\n",
      "Epoch 10 Batch 3354 Loss 4.4968\n",
      "Epoch 10 Batch 3612 Loss 4.4913\n",
      "Epoch 10 Batch 3870 Loss 4.4884\n",
      "Epoch 10 Batch 4128 Loss 4.4893\n",
      "Epoch 10 Batch 4386 Loss 4.4894\n",
      "Epoch 10 Batch 4644 Loss 4.4864\n",
      "Epoch 10 Batch 4902 Loss 4.4846\n",
      "Epoch 10 Batch 5160 Loss 4.4818\n",
      "Epoch 10 Batch 5418 Loss 4.4782\n",
      "Epoch 10 Batch 5676 Loss 4.4733\n",
      "Saving checkpoint for epoch 10 at checkpoints/ckpt-12\n",
      "Epoch 10 Loss 4.4710\n",
      "Time taken for 1 epoch: 3455.891407251358 secs\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 Batch 0 Loss 5.2428\n",
      "Epoch 11 Batch 258 Loss 4.6897\n",
      "Epoch 11 Batch 516 Loss 4.5195\n",
      "Epoch 11 Batch 774 Loss 4.4577\n",
      "Epoch 11 Batch 1032 Loss 4.4291\n",
      "Epoch 11 Batch 1290 Loss 4.4268\n",
      "Epoch 11 Batch 1548 Loss 4.4271\n",
      "Epoch 11 Batch 1806 Loss 4.4452\n",
      "Epoch 11 Batch 2064 Loss 4.4562\n",
      "Epoch 11 Batch 2322 Loss 4.4679\n",
      "Epoch 11 Batch 2580 Loss 4.4708\n",
      "Epoch 11 Batch 2838 Loss 4.4725\n",
      "Epoch 11 Batch 3096 Loss 4.4685\n",
      "Epoch 11 Batch 3354 Loss 4.4680\n",
      "Epoch 11 Batch 3612 Loss 4.4629\n",
      "Epoch 11 Batch 3870 Loss 4.4620\n",
      "Epoch 11 Batch 4128 Loss 4.4611\n",
      "Epoch 11 Batch 4386 Loss 4.4615\n",
      "Epoch 11 Batch 4644 Loss 4.4593\n",
      "Epoch 11 Batch 4902 Loss 4.4573\n",
      "Epoch 11 Batch 5160 Loss 4.4559\n",
      "Epoch 11 Batch 5418 Loss 4.4524\n",
      "Epoch 11 Batch 5676 Loss 4.4471\n",
      "Saving checkpoint for epoch 11 at checkpoints/ckpt-13\n",
      "Epoch 11 Loss 4.4445\n",
      "Time taken for 1 epoch: 3454.8984899520874 secs\n",
      "\n",
      "Epoch 12 Batch 0 Loss 4.8955\n",
      "Epoch 12 Batch 258 Loss 4.6651\n",
      "Epoch 12 Batch 516 Loss 4.4906\n",
      "Epoch 12 Batch 774 Loss 4.4411\n",
      "Epoch 12 Batch 1032 Loss 4.4118\n",
      "Epoch 12 Batch 1290 Loss 4.4076\n",
      "Epoch 12 Batch 1548 Loss 4.4078\n",
      "Epoch 12 Batch 1806 Loss 4.4270\n",
      "Epoch 12 Batch 2064 Loss 4.4361\n",
      "Epoch 12 Batch 2322 Loss 4.4456\n",
      "Epoch 12 Batch 2580 Loss 4.4479\n",
      "Epoch 12 Batch 2838 Loss 4.4509\n",
      "Epoch 12 Batch 3096 Loss 4.4464\n",
      "Epoch 12 Batch 3354 Loss 4.4464\n",
      "Epoch 12 Batch 3612 Loss 4.4422\n",
      "Epoch 12 Batch 3870 Loss 4.4389\n",
      "Epoch 12 Batch 4128 Loss 4.4396\n",
      "Epoch 12 Batch 4386 Loss 4.4405\n",
      "Epoch 12 Batch 4644 Loss 4.4380\n",
      "Epoch 12 Batch 4902 Loss 4.4368\n",
      "Epoch 12 Batch 5160 Loss 4.4343\n",
      "Epoch 12 Batch 5418 Loss 4.4308\n",
      "Epoch 12 Batch 5676 Loss 4.4251\n",
      "Saving checkpoint for epoch 12 at checkpoints/ckpt-14\n",
      "Epoch 12 Loss 4.4233\n",
      "Time taken for 1 epoch: 3454.6589856147766 secs\n",
      "\n",
      "Epoch 13 Batch 0 Loss 4.8880\n",
      "Epoch 13 Batch 258 Loss 4.6594\n",
      "Epoch 13 Batch 516 Loss 4.4926\n",
      "Epoch 13 Batch 774 Loss 4.4213\n",
      "Epoch 13 Batch 1032 Loss 4.3888\n",
      "Epoch 13 Batch 1290 Loss 4.3871\n",
      "Epoch 13 Batch 1548 Loss 4.3885\n",
      "Epoch 13 Batch 1806 Loss 4.4071\n",
      "Epoch 13 Batch 2064 Loss 4.4187\n",
      "Epoch 13 Batch 2322 Loss 4.4295\n",
      "Epoch 13 Batch 2580 Loss 4.4331\n",
      "Epoch 13 Batch 2838 Loss 4.4339\n",
      "Epoch 13 Batch 3096 Loss 4.4285\n",
      "Epoch 13 Batch 3354 Loss 4.4299\n",
      "Epoch 13 Batch 3612 Loss 4.4245\n",
      "Epoch 13 Batch 3870 Loss 4.4214\n",
      "Epoch 13 Batch 4128 Loss 4.4211\n",
      "Epoch 13 Batch 4386 Loss 4.4219\n",
      "Epoch 13 Batch 4644 Loss 4.4186\n",
      "Epoch 13 Batch 4902 Loss 4.4169\n",
      "Epoch 13 Batch 5160 Loss 4.4145\n",
      "Epoch 13 Batch 5418 Loss 4.4110\n",
      "Epoch 13 Batch 5676 Loss 4.4071\n",
      "Saving checkpoint for epoch 13 at checkpoints/ckpt-15\n",
      "Epoch 13 Loss 4.4040\n",
      "Time taken for 1 epoch: 3458.2506563663483 secs\n",
      "\n",
      "Epoch 14 Batch 0 Loss 5.3753\n",
      "Epoch 14 Batch 258 Loss 4.6440\n",
      "Epoch 14 Batch 516 Loss 4.4565\n",
      "Epoch 14 Batch 774 Loss 4.4014\n",
      "Epoch 14 Batch 1032 Loss 4.3711\n",
      "Epoch 14 Batch 1290 Loss 4.3698\n",
      "Epoch 14 Batch 1548 Loss 4.3682\n",
      "Epoch 14 Batch 1806 Loss 4.3875\n",
      "Epoch 14 Batch 2064 Loss 4.3974\n",
      "Epoch 14 Batch 2322 Loss 4.4059\n",
      "Epoch 14 Batch 2580 Loss 4.4097\n",
      "Epoch 14 Batch 2838 Loss 4.4131\n",
      "Epoch 14 Batch 3096 Loss 4.4089\n",
      "Epoch 14 Batch 3354 Loss 4.4078\n",
      "Epoch 14 Batch 3612 Loss 4.4041\n",
      "Epoch 14 Batch 3870 Loss 4.4007\n",
      "Epoch 14 Batch 4128 Loss 4.4010\n",
      "Epoch 14 Batch 4386 Loss 4.4013\n",
      "Epoch 14 Batch 4644 Loss 4.3998\n",
      "Epoch 14 Batch 4902 Loss 4.3977\n",
      "Epoch 14 Batch 5160 Loss 4.3956\n",
      "Epoch 14 Batch 5418 Loss 4.3932\n",
      "Epoch 14 Batch 5676 Loss 4.3871\n",
      "Saving checkpoint for epoch 14 at checkpoints/ckpt-16\n",
      "Epoch 14 Loss 4.3848\n",
      "Time taken for 1 epoch: 3452.1468267440796 secs\n",
      "\n",
      "Epoch 15 Batch 0 Loss 5.2524\n",
      "Epoch 15 Batch 258 Loss 4.6099\n",
      "Epoch 15 Batch 516 Loss 4.4386\n",
      "Epoch 15 Batch 774 Loss 4.3830\n",
      "Epoch 15 Batch 1032 Loss 4.3556\n",
      "Epoch 15 Batch 1290 Loss 4.3546\n",
      "Epoch 15 Batch 1548 Loss 4.3538\n",
      "Epoch 15 Batch 1806 Loss 4.3690\n",
      "Epoch 15 Batch 2064 Loss 4.3785\n",
      "Epoch 15 Batch 2322 Loss 4.3917\n",
      "Epoch 15 Batch 2580 Loss 4.3934\n",
      "Epoch 15 Batch 2838 Loss 4.3952\n",
      "Epoch 15 Batch 3096 Loss 4.3910\n",
      "Epoch 15 Batch 3354 Loss 4.3898\n",
      "Epoch 15 Batch 3612 Loss 4.3835\n",
      "Epoch 15 Batch 3870 Loss 4.3825\n",
      "Epoch 15 Batch 4128 Loss 4.3834\n",
      "Epoch 15 Batch 4386 Loss 4.3846\n",
      "Epoch 15 Batch 4644 Loss 4.3817\n",
      "Epoch 15 Batch 4902 Loss 4.3793\n",
      "Epoch 15 Batch 5160 Loss 4.3777\n",
      "Epoch 15 Batch 5418 Loss 4.3750\n",
      "Epoch 15 Batch 5676 Loss 4.3694\n",
      "Saving checkpoint for epoch 15 at checkpoints/ckpt-17\n",
      "Epoch 15 Loss 4.3671\n",
      "Time taken for 1 epoch: 3454.918552875519 secs\n",
      "\n",
      "Epoch 16 Batch 0 Loss 4.9225\n",
      "Epoch 16 Batch 258 Loss 4.5987\n",
      "Epoch 16 Batch 516 Loss 4.4371\n",
      "Epoch 16 Batch 774 Loss 4.3726\n",
      "Epoch 16 Batch 1032 Loss 4.3420\n",
      "Epoch 16 Batch 1290 Loss 4.3351\n",
      "Epoch 16 Batch 1548 Loss 4.3374\n",
      "Epoch 16 Batch 1806 Loss 4.3572\n",
      "Epoch 16 Batch 2064 Loss 4.3632\n",
      "Epoch 16 Batch 2322 Loss 4.3745\n",
      "Epoch 16 Batch 2580 Loss 4.3768\n",
      "Epoch 16 Batch 2838 Loss 4.3805\n",
      "Epoch 16 Batch 3096 Loss 4.3761\n",
      "Epoch 16 Batch 3354 Loss 4.3761\n",
      "Epoch 16 Batch 3612 Loss 4.3699\n",
      "Epoch 16 Batch 3870 Loss 4.3679\n",
      "Epoch 16 Batch 4128 Loss 4.3668\n",
      "Epoch 16 Batch 4386 Loss 4.3686\n",
      "Epoch 16 Batch 4644 Loss 4.3658\n",
      "Epoch 16 Batch 4902 Loss 4.3643\n",
      "Epoch 16 Batch 5160 Loss 4.3613\n",
      "Epoch 16 Batch 5418 Loss 4.3592\n",
      "Epoch 16 Batch 5676 Loss 4.3543\n",
      "Saving checkpoint for epoch 16 at checkpoints/ckpt-18\n",
      "Epoch 16 Loss 4.3525\n",
      "Time taken for 1 epoch: 3555.944089651108 secs\n",
      "\n",
      "Epoch 17 Batch 0 Loss 5.0143\n",
      "Epoch 17 Batch 258 Loss 4.5859\n",
      "Epoch 17 Batch 516 Loss 4.4153\n",
      "Epoch 17 Batch 774 Loss 4.3643\n",
      "Epoch 17 Batch 1032 Loss 4.3305\n",
      "Epoch 17 Batch 1290 Loss 4.3208\n",
      "Epoch 17 Batch 1548 Loss 4.3219\n",
      "Epoch 17 Batch 1806 Loss 4.3372\n",
      "Epoch 17 Batch 2064 Loss 4.3495\n",
      "Epoch 17 Batch 2322 Loss 4.3605\n",
      "Epoch 17 Batch 2580 Loss 4.3615\n",
      "Epoch 17 Batch 2838 Loss 4.3621\n",
      "Epoch 17 Batch 3096 Loss 4.3575\n",
      "Epoch 17 Batch 3354 Loss 4.3567\n",
      "Epoch 17 Batch 3612 Loss 4.3516\n",
      "Epoch 17 Batch 3870 Loss 4.3513\n",
      "Epoch 17 Batch 4128 Loss 4.3516\n",
      "Epoch 17 Batch 4386 Loss 4.3514\n",
      "Epoch 17 Batch 4644 Loss 4.3493\n",
      "Epoch 17 Batch 4902 Loss 4.3475\n",
      "Epoch 17 Batch 5160 Loss 4.3455\n",
      "Epoch 17 Batch 5418 Loss 4.3424\n",
      "Epoch 17 Batch 5676 Loss 4.3371\n",
      "Saving checkpoint for epoch 17 at checkpoints/ckpt-19\n",
      "Epoch 17 Loss 4.3352\n",
      "Time taken for 1 epoch: 3454.722646713257 secs\n",
      "\n",
      "Epoch 18 Batch 0 Loss 5.1499\n",
      "Epoch 18 Batch 258 Loss 4.5600\n",
      "Epoch 18 Batch 516 Loss 4.3922\n",
      "Epoch 18 Batch 774 Loss 4.3399\n",
      "Epoch 18 Batch 1032 Loss 4.3101\n",
      "Epoch 18 Batch 1290 Loss 4.3050\n",
      "Epoch 18 Batch 1548 Loss 4.3047\n",
      "Epoch 18 Batch 1806 Loss 4.3263\n",
      "Epoch 18 Batch 2064 Loss 4.3324\n",
      "Epoch 18 Batch 2322 Loss 4.3412\n",
      "Epoch 18 Batch 2580 Loss 4.3454\n",
      "Epoch 18 Batch 2838 Loss 4.3459\n",
      "Epoch 18 Batch 3096 Loss 4.3428\n",
      "Epoch 18 Batch 3354 Loss 4.3430\n",
      "Epoch 18 Batch 3612 Loss 4.3369\n",
      "Epoch 18 Batch 3870 Loss 4.3345\n",
      "Epoch 18 Batch 4128 Loss 4.3350\n",
      "Epoch 18 Batch 4386 Loss 4.3349\n",
      "Epoch 18 Batch 4644 Loss 4.3325\n",
      "Epoch 18 Batch 4902 Loss 4.3309\n",
      "Epoch 18 Batch 5160 Loss 4.3301\n",
      "Epoch 18 Batch 5418 Loss 4.3276\n",
      "Epoch 18 Batch 5676 Loss 4.3226\n",
      "Saving checkpoint for epoch 18 at checkpoints/ckpt-20\n",
      "Epoch 18 Loss 4.3205\n",
      "Time taken for 1 epoch: 3452.266204357147 secs\n",
      "\n",
      "Epoch 19 Batch 0 Loss 4.9385\n",
      "Epoch 19 Batch 258 Loss 4.5455\n",
      "Epoch 19 Batch 516 Loss 4.3782\n",
      "Epoch 19 Batch 774 Loss 4.3292\n",
      "Epoch 19 Batch 1032 Loss 4.2981\n",
      "Epoch 19 Batch 1290 Loss 4.2940\n",
      "Epoch 19 Batch 1548 Loss 4.2913\n",
      "Epoch 19 Batch 1806 Loss 4.3081\n",
      "Epoch 19 Batch 2064 Loss 4.3184\n",
      "Epoch 19 Batch 2322 Loss 4.3280\n",
      "Epoch 19 Batch 2580 Loss 4.3316\n",
      "Epoch 19 Batch 2838 Loss 4.3328\n",
      "Epoch 19 Batch 3096 Loss 4.3286\n",
      "Epoch 19 Batch 3354 Loss 4.3281\n",
      "Epoch 19 Batch 3612 Loss 4.3232\n",
      "Epoch 19 Batch 3870 Loss 4.3203\n",
      "Epoch 19 Batch 4128 Loss 4.3210\n",
      "Epoch 19 Batch 4386 Loss 4.3224\n",
      "Epoch 19 Batch 4644 Loss 4.3199\n",
      "Epoch 19 Batch 4902 Loss 4.3175\n",
      "Epoch 19 Batch 5160 Loss 4.3159\n",
      "Epoch 19 Batch 5418 Loss 4.3136\n",
      "Epoch 19 Batch 5676 Loss 4.3099\n",
      "Saving checkpoint for epoch 19 at checkpoints/ckpt-21\n",
      "Epoch 19 Loss 4.3072\n",
      "Time taken for 1 epoch: 3445.2018435001373 secs\n",
      "\n",
      "Epoch 20 Batch 0 Loss 4.6537\n",
      "Epoch 20 Batch 258 Loss 4.5247\n",
      "Epoch 20 Batch 516 Loss 4.3783\n",
      "Epoch 20 Batch 774 Loss 4.3150\n",
      "Epoch 20 Batch 1032 Loss 4.2799\n",
      "Epoch 20 Batch 1290 Loss 4.2774\n",
      "Epoch 20 Batch 1548 Loss 4.2779\n",
      "Epoch 20 Batch 1806 Loss 4.2932\n",
      "Epoch 20 Batch 2064 Loss 4.3071\n",
      "Epoch 20 Batch 2322 Loss 4.3166\n",
      "Epoch 20 Batch 2580 Loss 4.3192\n",
      "Epoch 20 Batch 2838 Loss 4.3224\n",
      "Epoch 20 Batch 3096 Loss 4.3164\n",
      "Epoch 20 Batch 3354 Loss 4.3156\n",
      "Epoch 20 Batch 3612 Loss 4.3120\n",
      "Epoch 20 Batch 3870 Loss 4.3093\n",
      "Epoch 20 Batch 4128 Loss 4.3097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 Batch 4386 Loss 4.3098\n",
      "Epoch 20 Batch 4644 Loss 4.3076\n",
      "Epoch 20 Batch 4902 Loss 4.3048\n",
      "Epoch 20 Batch 5160 Loss 4.3036\n",
      "Epoch 20 Batch 5418 Loss 4.3021\n",
      "Epoch 20 Batch 5676 Loss 4.2969\n",
      "Saving checkpoint for epoch 20 at checkpoints/ckpt-22\n",
      "Epoch 20 Loss 4.2944\n",
      "Time taken for 1 epoch: 3447.408590078354 secs\n",
      "\n",
      "Epoch 21 Batch 0 Loss 4.7913\n",
      "Epoch 21 Batch 258 Loss 4.5332\n",
      "Epoch 21 Batch 516 Loss 4.3665\n",
      "Epoch 21 Batch 774 Loss 4.3066\n",
      "Epoch 21 Batch 1032 Loss 4.2738\n",
      "Epoch 21 Batch 1290 Loss 4.2703\n",
      "Epoch 21 Batch 1548 Loss 4.2704\n",
      "Epoch 21 Batch 1806 Loss 4.2835\n",
      "Epoch 21 Batch 2064 Loss 4.2948\n",
      "Epoch 21 Batch 2322 Loss 4.3046\n",
      "Epoch 21 Batch 2580 Loss 4.3091\n",
      "Epoch 21 Batch 2838 Loss 4.3102\n",
      "Epoch 21 Batch 3096 Loss 4.3044\n",
      "Epoch 21 Batch 3354 Loss 4.3041\n",
      "Epoch 21 Batch 3612 Loss 4.2990\n",
      "Epoch 21 Batch 3870 Loss 4.2974\n",
      "Epoch 21 Batch 4128 Loss 4.2981\n",
      "Epoch 21 Batch 4386 Loss 4.2997\n",
      "Epoch 21 Batch 4644 Loss 4.2967\n",
      "Epoch 21 Batch 4902 Loss 4.2951\n",
      "Epoch 21 Batch 5160 Loss 4.2929\n",
      "Epoch 21 Batch 5418 Loss 4.2920\n",
      "Epoch 21 Batch 5676 Loss 4.2870\n",
      "Saving checkpoint for epoch 21 at checkpoints/ckpt-23\n",
      "Epoch 21 Loss 4.2847\n",
      "Time taken for 1 epoch: 3446.446005821228 secs\n",
      "\n",
      "Epoch 22 Batch 0 Loss 4.9660\n",
      "Epoch 22 Batch 258 Loss 4.5042\n",
      "Epoch 22 Batch 516 Loss 4.3466\n",
      "Epoch 22 Batch 774 Loss 4.2928\n",
      "Epoch 22 Batch 1032 Loss 4.2677\n",
      "Epoch 22 Batch 1290 Loss 4.2604\n",
      "Epoch 22 Batch 1548 Loss 4.2575\n",
      "Epoch 22 Batch 1806 Loss 4.2748\n",
      "Epoch 22 Batch 2064 Loss 4.2833\n",
      "Epoch 22 Batch 2322 Loss 4.2931\n",
      "Epoch 22 Batch 2580 Loss 4.2970\n",
      "Epoch 22 Batch 2838 Loss 4.2982\n",
      "Epoch 22 Batch 3096 Loss 4.2931\n",
      "Epoch 22 Batch 3354 Loss 4.2925\n",
      "Epoch 22 Batch 3612 Loss 4.2887\n",
      "Epoch 22 Batch 3870 Loss 4.2869\n",
      "Epoch 22 Batch 4128 Loss 4.2877\n",
      "Epoch 22 Batch 4386 Loss 4.2875\n",
      "Epoch 22 Batch 4644 Loss 4.2845\n",
      "Epoch 22 Batch 4902 Loss 4.2834\n",
      "Epoch 22 Batch 5160 Loss 4.2823\n",
      "Epoch 22 Batch 5418 Loss 4.2803\n",
      "Epoch 22 Batch 5676 Loss 4.2762\n",
      "Saving checkpoint for epoch 22 at checkpoints/ckpt-24\n",
      "Epoch 22 Loss 4.2741\n",
      "Time taken for 1 epoch: 3458.7859494686127 secs\n",
      "\n",
      "Epoch 23 Batch 0 Loss 4.7789\n",
      "Epoch 23 Batch 258 Loss 4.4951\n",
      "Epoch 23 Batch 516 Loss 4.3305\n",
      "Epoch 23 Batch 774 Loss 4.2777\n",
      "Epoch 23 Batch 1032 Loss 4.2462\n",
      "Epoch 23 Batch 1290 Loss 4.2469\n",
      "Epoch 23 Batch 1548 Loss 4.2420\n",
      "Epoch 23 Batch 1806 Loss 4.2575\n",
      "Epoch 23 Batch 2064 Loss 4.2686\n",
      "Epoch 23 Batch 2322 Loss 4.2817\n",
      "Epoch 23 Batch 2580 Loss 4.2843\n",
      "Epoch 23 Batch 2838 Loss 4.2868\n",
      "Epoch 23 Batch 3096 Loss 4.2811\n",
      "Epoch 23 Batch 3354 Loss 4.2804\n",
      "Epoch 23 Batch 3612 Loss 4.2762\n",
      "Epoch 23 Batch 3870 Loss 4.2738\n",
      "Epoch 23 Batch 4128 Loss 4.2754\n",
      "Epoch 23 Batch 4386 Loss 4.2762\n",
      "Epoch 23 Batch 4644 Loss 4.2747\n",
      "Epoch 23 Batch 4902 Loss 4.2730\n",
      "Epoch 23 Batch 5160 Loss 4.2722\n",
      "Epoch 23 Batch 5418 Loss 4.2695\n",
      "Epoch 23 Batch 5676 Loss 4.2655\n",
      "Saving checkpoint for epoch 23 at checkpoints/ckpt-25\n",
      "Epoch 23 Loss 4.2642\n",
      "Time taken for 1 epoch: 3452.7214765548706 secs\n",
      "\n",
      "Epoch 24 Batch 0 Loss 4.6197\n",
      "Epoch 24 Batch 258 Loss 4.4875\n",
      "Epoch 24 Batch 516 Loss 4.3065\n",
      "Epoch 24 Batch 774 Loss 4.2619\n",
      "Epoch 24 Batch 1032 Loss 4.2321\n",
      "Epoch 24 Batch 1290 Loss 4.2311\n",
      "Epoch 24 Batch 1548 Loss 4.2346\n",
      "Epoch 24 Batch 1806 Loss 4.2507\n",
      "Epoch 24 Batch 2064 Loss 4.2634\n",
      "Epoch 24 Batch 2322 Loss 4.2726\n",
      "Epoch 24 Batch 2580 Loss 4.2785\n",
      "Epoch 24 Batch 2838 Loss 4.2789\n",
      "Epoch 24 Batch 3096 Loss 4.2738\n",
      "Epoch 24 Batch 3354 Loss 4.2741\n",
      "Epoch 24 Batch 3612 Loss 4.2701\n",
      "Epoch 24 Batch 3870 Loss 4.2686\n",
      "Epoch 24 Batch 4128 Loss 4.2716\n",
      "Epoch 24 Batch 4386 Loss 4.2726\n",
      "Epoch 24 Batch 4644 Loss 4.2702\n",
      "Epoch 24 Batch 4902 Loss 4.2694\n",
      "Epoch 24 Batch 5160 Loss 4.2679\n",
      "Epoch 24 Batch 5418 Loss 4.2650\n",
      "Epoch 24 Batch 5676 Loss 4.2605\n",
      "Saving checkpoint for epoch 24 at checkpoints/ckpt-26\n",
      "Epoch 24 Loss 4.2580\n",
      "Time taken for 1 epoch: 3443.3878226280212 secs\n",
      "\n",
      "Epoch 25 Batch 0 Loss 4.9781\n",
      "Epoch 25 Batch 258 Loss 4.4738\n",
      "Epoch 25 Batch 516 Loss 4.2932\n",
      "Epoch 25 Batch 774 Loss 4.2450\n",
      "Epoch 25 Batch 1032 Loss 4.2183\n",
      "Epoch 25 Batch 1290 Loss 4.2182\n",
      "Epoch 25 Batch 1548 Loss 4.2190\n",
      "Epoch 25 Batch 1806 Loss 4.2377\n",
      "Epoch 25 Batch 2064 Loss 4.2497\n",
      "Epoch 25 Batch 2322 Loss 4.2597\n",
      "Epoch 25 Batch 2580 Loss 4.2658\n",
      "Epoch 25 Batch 2838 Loss 4.2678\n",
      "Epoch 25 Batch 3096 Loss 4.2647\n",
      "Epoch 25 Batch 3354 Loss 4.2671\n",
      "Epoch 25 Batch 3612 Loss 4.2650\n",
      "Epoch 25 Batch 3870 Loss 4.2634\n",
      "Epoch 25 Batch 4128 Loss 4.2638\n",
      "Epoch 25 Batch 4386 Loss 4.2663\n",
      "Epoch 25 Batch 4644 Loss 4.2656\n",
      "Epoch 25 Batch 4902 Loss 4.2654\n",
      "Epoch 25 Batch 5160 Loss 4.2640\n",
      "Epoch 25 Batch 5418 Loss 4.2613\n",
      "Epoch 25 Batch 5676 Loss 4.2577\n",
      "Saving checkpoint for epoch 25 at checkpoints/ckpt-27\n",
      "Epoch 25 Loss 4.2553\n",
      "Time taken for 1 epoch: 3506.424457550049 secs\n",
      "\n",
      "Epoch 26 Batch 0 Loss 5.0271\n",
      "Epoch 26 Batch 258 Loss 4.4346\n",
      "Epoch 26 Batch 516 Loss 4.2806\n",
      "Epoch 26 Batch 774 Loss 4.2324\n",
      "Epoch 26 Batch 1032 Loss 4.2074\n",
      "Epoch 26 Batch 1290 Loss 4.2070\n",
      "Epoch 26 Batch 1548 Loss 4.2109\n",
      "Epoch 26 Batch 1806 Loss 4.2279\n",
      "Epoch 26 Batch 2064 Loss 4.2370\n",
      "Epoch 26 Batch 2322 Loss 4.2478\n",
      "Epoch 26 Batch 2580 Loss 4.2546\n",
      "Epoch 26 Batch 2838 Loss 4.2581\n",
      "Epoch 26 Batch 3096 Loss 4.2536\n",
      "Epoch 26 Batch 3354 Loss 4.2546\n",
      "Epoch 26 Batch 3612 Loss 4.2523\n",
      "Epoch 26 Batch 3870 Loss 4.2516\n",
      "Epoch 26 Batch 4128 Loss 4.2547\n",
      "Epoch 26 Batch 4386 Loss 4.2564\n",
      "Epoch 26 Batch 4644 Loss 4.2550\n",
      "Epoch 26 Batch 4902 Loss 4.2551\n",
      "Epoch 26 Batch 5160 Loss 4.2543\n",
      "Epoch 26 Batch 5418 Loss 4.2526\n",
      "Epoch 26 Batch 5676 Loss 4.2481\n",
      "Saving checkpoint for epoch 26 at checkpoints/ckpt-28\n",
      "Epoch 26 Loss 4.2460\n",
      "Time taken for 1 epoch: 3460.367491006851 secs\n",
      "\n",
      "Epoch 27 Batch 0 Loss 4.7060\n",
      "Epoch 27 Batch 258 Loss 4.4114\n",
      "Epoch 27 Batch 516 Loss 4.2468\n",
      "Epoch 27 Batch 774 Loss 4.2135\n",
      "Epoch 27 Batch 1032 Loss 4.1986\n",
      "Epoch 27 Batch 1290 Loss 4.2010\n",
      "Epoch 27 Batch 1548 Loss 4.2039\n",
      "Epoch 27 Batch 1806 Loss 4.2196\n",
      "Epoch 27 Batch 2064 Loss 4.2280\n",
      "Epoch 27 Batch 2322 Loss 4.2372\n",
      "Epoch 27 Batch 2580 Loss 4.2425\n",
      "Epoch 27 Batch 2838 Loss 4.2460\n",
      "Epoch 27 Batch 3096 Loss 4.2444\n",
      "Epoch 27 Batch 3354 Loss 4.2463\n",
      "Epoch 27 Batch 3612 Loss 4.2432\n",
      "Epoch 27 Batch 3870 Loss 4.2426\n",
      "Epoch 27 Batch 4128 Loss 4.2441\n",
      "Epoch 27 Batch 4386 Loss 4.2457\n",
      "Epoch 27 Batch 4644 Loss 4.2442\n",
      "Epoch 27 Batch 4902 Loss 4.2446\n",
      "Epoch 27 Batch 5160 Loss 4.2444\n",
      "Epoch 27 Batch 5418 Loss 4.2425\n",
      "Epoch 27 Batch 5676 Loss 4.2387\n",
      "Saving checkpoint for epoch 27 at checkpoints/ckpt-29\n",
      "Epoch 27 Loss 4.2360\n",
      "Time taken for 1 epoch: 3457.1401932239532 secs\n",
      "\n",
      "Epoch 28 Batch 0 Loss 4.8904\n",
      "Epoch 28 Batch 258 Loss 4.4040\n",
      "Epoch 28 Batch 516 Loss 4.2434\n",
      "Epoch 28 Batch 774 Loss 4.2067\n",
      "Epoch 28 Batch 1032 Loss 4.1933\n",
      "Epoch 28 Batch 1290 Loss 4.1946\n",
      "Epoch 28 Batch 1548 Loss 4.1938\n",
      "Epoch 28 Batch 1806 Loss 4.2096\n",
      "Epoch 28 Batch 2064 Loss 4.2205\n",
      "Epoch 28 Batch 2322 Loss 4.2303\n",
      "Epoch 28 Batch 2580 Loss 4.2354\n",
      "Epoch 28 Batch 2838 Loss 4.2369\n",
      "Epoch 28 Batch 3096 Loss 4.2352\n",
      "Epoch 28 Batch 3354 Loss 4.2378\n",
      "Epoch 28 Batch 3612 Loss 4.2352\n",
      "Epoch 28 Batch 3870 Loss 4.2344\n",
      "Epoch 28 Batch 4128 Loss 4.2368\n",
      "Epoch 28 Batch 4386 Loss 4.2381\n",
      "Epoch 28 Batch 4644 Loss 4.2377\n",
      "Epoch 28 Batch 4902 Loss 4.2377\n",
      "Epoch 28 Batch 5160 Loss 4.2367\n",
      "Epoch 28 Batch 5418 Loss 4.2344\n",
      "Epoch 28 Batch 5676 Loss 4.2294\n",
      "Saving checkpoint for epoch 28 at checkpoints/ckpt-30\n",
      "Epoch 28 Loss 4.2271\n",
      "Time taken for 1 epoch: 3460.7135536670685 secs\n",
      "\n",
      "Epoch 29 Batch 0 Loss 4.7588\n",
      "Epoch 29 Batch 258 Loss 4.3977\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-072d639d3124>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m# 55k samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "\n",
    "    train_loss.reset_states()\n",
    "  \n",
    "    for (batch, (inp, tar)) in enumerate(dataset):\n",
    "        train_step(inp, tar)\n",
    "    \n",
    "        # 55k samples\n",
    "        # we display 3 batch results -- 0th, middle and last one (approx)\n",
    "        # 55k / 64 ~ 858; 858 / 2 = 429\n",
    "        if batch % 258 == 0:\n",
    "            print ('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1, batch, train_loss.result()))\n",
    "      \n",
    "    #if (epoch + 1) % 5 == 0:\n",
    "        #ckpt_save_path = ckpt_manager.save()\n",
    "        #print ('Saving checkpoint for epoch {} at {}'.format(epoch+1, ckpt_save_path))\n",
    "    ckpt_save_path = ckpt_manager.save()\n",
    "    print ('Saving checkpoint for epoch {} at {}'.format(epoch+1, ckpt_save_path))\n",
    "    print ('Epoch {} Loss {:.4f}'.format(epoch + 1, train_loss.result()))\n",
    "\n",
    "    print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PVbEUCZagJ0G"
   },
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YMbqGTixu1cl"
   },
   "source": [
    "#### Predicting one word at a time at the decoder and appending it to the output; then taking the complete sequence as an input to the decoder and repeating until maxlen or stop keyword appears"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F5D5cv2Jd8-6"
   },
   "outputs": [],
   "source": [
    "def evaluate(input_document):\n",
    "    input_document = cleaned_text(input_document)\n",
    "    input_document = document_tokenizer.EncodeAsIds(input_document)\n",
    "    input_document = tf.keras.preprocessing.sequence.pad_sequences([input_document], maxlen=encoder_maxlen, padding='post', truncating='post')\n",
    "    encoder_input = tf.expand_dims(input_document[0], 0)\n",
    "\n",
    "    decoder_input = [1] #[BOS] index\n",
    "    output = tf.expand_dims(decoder_input, 0)\n",
    "    \n",
    "    for i in range(decoder_maxlen):\n",
    "        enc_padding_mask, combined_mask, dec_padding_mask = create_masks(encoder_input, output)\n",
    "\n",
    "        predictions, attention_weights = transformer(\n",
    "            encoder_input, \n",
    "            output,\n",
    "            False,\n",
    "            enc_padding_mask,\n",
    "            combined_mask,\n",
    "            dec_padding_mask\n",
    "        )\n",
    "\n",
    "        predictions = predictions[: ,-1:, :]\n",
    "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "        if predicted_id == 2: #[EOS] index\n",
    "            return tf.squeeze(output, axis=0), attention_weights\n",
    "\n",
    "        output = tf.concat([output, predicted_id], axis=-1)\n",
    "\n",
    "    return tf.squeeze(output, axis=0), attention_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UkpdiW6wnmiS"
   },
   "outputs": [],
   "source": [
    "def summarize(input_document):\n",
    "    # not considering attention weights for now, can be used to plot attention heatmaps in the future\n",
    "    summarized = evaluate(input_document=input_document)[0].numpy()\n",
    "    summarized = np.expand_dims(summarized, 0)\n",
    "    print(summarized[0].tolist())\n",
    "    return summary_tokenizer.DecodeIds(summarized[0].tolist())  # since there is just one translated document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 100(정치)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 19, 335, 228, 4, 10, 51245, 402, 10, 99982, 29, 62, 108, 16050, 4, 55, 89, 1322, 16, 15, 871, 559, 14, 593]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'“文정부, 이체하고 묻은 것”...페북, 4개 기관에 ‘디지털 뉴딜’ 요구'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize('여권 차기 대선주자군에서 더불어민주당 이낙연 대표와 함께 ‘양강’으로 꼽히는 이재명 경기지사가 1일 스가 요시히데 일본 총리가 한국을 방문하는 일은 없을 것이라고 단언했다. 민족의 명절인 추석날에 일본 총리에 대한 실망감을 드러내며 ‘반일 이미지’를 부각한 셈이다. 최근 여론조사에서 이 대표 지지율이 근소한 차로 1위를 되찾으며 상승세를 탄 것과 무관치 않다는 분석이 나온다. 이 지사는 이날 자신의 페이스북에 ‘스가총리가 방한할 일은 없겠습니다’라는 제목의 글을 올려 “명확한 3권분립으로 정치의 사법 개입이 금지된 대한민국은 정치의 사법 판결 개입은 불법이고 상식적으로 있을 수 없는 일이기 때문에 일본의 ‘징용판결에 대한 정치개입’ 요구를 이해할 수도, 수용할 수도 없다”고 지적했다. 이어 “법적으로나 국민감정으로나 수용 불가능한 조건을 내세우는 것을 보니 스가총리가 방한할 일은 없을 것 같다”고 주장했다. ‘한국이 피고인 일본 기업 자산을 매각하지 않는다고 약속해야 스가 총리가 방한할 수 있다’는 한 일본 관리 발언에 대한 반응으로 보이는 이 지사의 이같은 언급은 이 대표와는 대비된다. 이 대표는 스가 총리 취임을 계기로 “일본의 국운이 상승하고 한·일관계가 개선되길 바란다”며 기대감을 밝힌 바 있다. 이 지사는 “일본과 한국은 복잡하고 미묘한 역사적, 국제정치학적, 외교군사적, 경제사회적 문제들을 해결하기 위해 정치외교와 경제사회 분리, 상호존중과 이해라는 큰 원칙을 지켜야 한다”며 “일본이 아무리 부인해도 침략과 잔혹한 인권침해의 역사는 대한민국에게 역사적 진실이자, 현실”이라고 못박았다. 그는 “위안부, 강제노역 문제는 누가 뭐라하든 가해자인 일본이 만든 문제”라며 “진정한 화해를 위한 사과는 피해자가 용서하고 그만하라 할 때까지 진심으로 하는 것이지 ‘옜다, 사과’로 쉽게 끝낼 수 있는 것이 아니다”고 강조했다. 그러면서 “일본과 한국은 복잡하고 미묘한 역사적, 국제정치학적, 외교 군사적, 경제 사회적 문제들을 해결하기 위해 정치 외교와 경제사회 분리, 상호존중과 이해라는 큰 원칙을 지켜야 한다”고 주문했다.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이재명 \"징용판결 '정치개입' 요구한 스가, 방한할 일 없을 것\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1513, 4, 183, 34, 8, 54, 25, 6, 282, 1049, 2872, 5, 244, 11, 525, 768, 251]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"EU, 2020년 '코로나19' 대응 전략 수립...美·中 갈등 확산\""
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize('문재인 대통령이 세계무역기구(WTO) 사무총장 선거에 출마한 유명희 산업통상자원부 통상교섭본부장을 돕기 위해 적극 나섰다. 추석인 1일 앙겔라 메르켈 독일 총리와 정상통화를 갖고 유 본부장 지지를 당부했다. 통화는 문 대통령 제의로 이날 오후 6시부터 약 20분간 이어졌다. 양국 정상의 직접 소통은 약 2년만이다. 두 정상은 2018년 10월 아셈(ASEM·아시아유럽정상회의) 정상회의를 계기로 벨기에 브뤼셀에서 정상회담을 한 바 있다. 문 대통령은 지난달 24일엔 유 본부장 지지 요청 서한을 독일 측에 전달한 바 있다. 문 대통령은 이날 통화에서 “한국은 자유무역질서 속에서 성장해왔고 다자무역체제의 수호와 발전이 WTO 중심으로 이뤄져야 한다는 확고한 신념을 갖고 있다”고 설명했다. 그러면서 “유 본부장은 이런 신념을 실현할 수 있는 비전과 역량을 갖추고 있고 WTO를 발전시키고 신뢰를 회복시킬 수 있는 최적임자라고 생각한다”고 강조했다. 메르켈 총리는 “한국의 유명희 후보가 능력과 전문성을 갖춘 적임자로 보고 있다”고 화답했다고 청와대는 전했다. 문 대통령은 또 오는 3일 독일이 통일 30주년을 맞는 것에 대해 “한반도 평화와 통일을 희망하는 우리 국민들에게도 많은 영감을 주는 의미있는 날”이라며 축하의 뜻을 전했다. 이어 “코로나19(신종 코로나바이러스 감염증) 상황이 전세계적으로 다시 악화하면서 우려가 클 것”이라면서 “그동안 (메르켈) 총리 리더십 하에 독일이 코로나19 대응에 모범이 돼온 것에 경의를 표한다”고 밝혔다. “앞으로도 인류가 코로나 위기를 극복하는데 선도적인 역할을 해 줄 것으로 기대한다”는 덕담도 곁들였다. 메르켈 총리는 “한국이 통일에 대해 꾸는 꿈을 잘 알고 있다”며 “성대하게 독일통일 30주년 행사를 치르고 싶었으나 코로나19 때문에 그러지 못해 유감”이라고 말했다. 또 “코로나19 확산을 막아온 한국의 대처 방식에 큰 관심이 있다”고 전했다.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 文 대통령 “유명희 지지 요청”… 메르켈 “전문성 갖춘 적임자”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 101(경제)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 8, 871, 2574, 6, 132, 297]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"'디지털 교도소' 운영 중단\""
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize('[파이낸셜뉴스] 손병석 한국철도(코레일) 사장이 1일 오후 경기도 고양에 있는 수도권철도차량정비단을 찾아 KTX 정비상황을 점검했다. 손병석 사장은 KTX 열차 운행 전 유지관리 상황을 살피고 만일의 상황을 대비한 비상대응체계를 점검했다. 손병석 사장은 “추석 대수송기간 KTX 열차 운행이 늘어난 만큼 더욱 꼼꼼한 정비가 필요하다”며 “특히 방역과 차내설비 점검에 만전을 기해 국민들이 안심하고 편안히 고향을 다녀올 수 있도록 최선을 다해달라”고 강조하고 직원들을 격려했다. 한편 한국철도는 4일까지를 추석 특별교통대책기간으로 정하고, 특별교통대책본부를 24시간 운영하고 있다.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 손병석 한국철도 사장, 고양 KTX차량기지 안전 점검"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 9, 10340, 165, 6490, 21, 92, 886, 40, 54, 25, 16, 1149, 94, 261, 1725]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\"신생아 투자하려면도 안 돼\"...코로나19에 태풍까지 피해 속출'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize(\"[아시아경제 조강욱 기자] 신용이 개선된 대출 고객들이 은행에 금리 인하를 요구해 3년 반 동안 아낀 돈이 1130억원을 넘어선 것으로 나타났다. 1일 국회 정무위원회 간사인 더불어민주당 김병욱 의원이 금융감독원으로부터 제출받은 자료에 따르면 KB국민ㆍ신한ㆍ우리ㆍ하나ㆍSC제일ㆍ씨티ㆍ기업은행과 케이ㆍ카카오뱅크에 올해 상반기 접수된 금리 인하 요구는 33만8082건으로 집계됐다. 2017년 11만371건에서 2018년 22만8558건, 2019년 47만8150건으로 늘어난 데 이어 증가세가 더 가팔라진 추세다. 금리인하요구권은 신용평가 등급이 올랐거나 취업ㆍ승진을 했을 때, 재산이 늘었을 때 개선된 신용 상태를 반영해 대출 이자를 깎아달라고 요구할 수 있는 권리로 지난해 6월 법제화를 계기로 활성화됐다. 특히 전체 금리 인하 요구 중 비대면 신청의 비중은 2017년 60.3%에서 2018년 85.9%, 2019년 95.2%, 2020년 상반기 98.2%로 급증했다. 대부분이 은행 지점 방문 없이 손쉽게 온라인으로 대출 이자를 아끼고 있는 것이다. 금리인하요구권 수용 건수는 2017년 4만5820건에서 2018년 6만877건, 2019년 14만3059건, 올 상반기 14만3059건으로 늘었다. 또 수용에 따른 이자 절감 추정액은 같은 기간 438억800만원, 327억9200만원, 277억3100만원, 93억2200만원 등으로 매년 감소했다. 금리인하요구권 수용률은 2017년 41.5%, 2018년 26.6%, 2019년 29.9%, 올해 상반기 32.5% 수준이었다. 김병욱 의원은 '더 많은 국민이 자신의 권리를 누리고 혜택을 받을 수 있도록 은행권과 금융당국이 적극적으로 금리인하요구권을 홍보하고 수용률 제고를 위해 노력해야 한다'고 강조했다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 금리인하 비대면 신청 급증…3년간 아낀 이자 '1100억'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 105(IT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 10610, 4, 8, 16207, 28727, 30015, 6, 358, 69]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"MS, '로드 오브 히어로즈' 글로벌 출시\""
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize(\"(서울=연합뉴스) 이효석 기자 = 마이크로소프트(MS)는 신형 노트북 '서피스 랩탑 고'(Suface Laptop Go)를 출시한다고 1일 발표했다. MS는 '신종 코로나바이러스 감염증(코로나19)으로 인한 재택근무와 비대면 학습 환경이 장기화하고 있다'면서 '뉴노멀 시대 연결성을 지원하기 위해 서피스 제품의 디자인·색상·가격대를 다양화한다'고 밝혔다. 국내 출시 일정과 가격은 정해지지 않았다. 서피스 랩탑 고는 그동안 출시된 서피스 랩탑 중 가장 가볍고 합리적인 가격으로 나온다고 MS는 설명했다. 12.4인치 픽셀 센스 터치스크린 디스플레이가 장착됐고, 대형 트랙패드와 1.3㎜ 키보드가 정확한 타이핑을 돕는다. 16GB RAM과 256GB 스토리지, 인텔 10세대 i5 쿼드코어 프로세서가 탑재됐다. 구성은 성능과 배터리 수명에 최적화됐다. 배터리 사용시간은 최대 13시간이다. 색상은 아이스 블루, 샌드스톤, 플래티넘 등 3가지로 출시된다. 720p HD 카메라와 스튜디오 마이크는 원격 근무 또는 학습을 지원한다. 옴니소닉 스피커와 돌비 오디오는 영상 통화나 영화·음악 감상 경험을 배가한다. 서피스 랩탑 고는 원터치 지문 인식 로그인 기능으로 안전한 로그인도 지원한다. 원터치 로그인 기능은 원드라이브(OneDrive)의 개인 파일 접근에도 연동된다. MS는 '마이크로소프트365와 온라인 저장 공간 등 클라우드 연결 경험을 극대화했다'면서 '서피스 제품을 처음 쓰는 초보자도 빠르게 적용할 수 있을 것'이라고 덧붙였다. 서피스 프로 X [마이크로소프트 제공. 재판매 및 DB 금지] 이날 MS는 지난해 10월 출시한 태블릿 PC '서피스 프로 X'(Surface Pro X)의 업데이트 버전도 출시한다고 발표했다. 서피스 프로 X 업데이트 버전은 차세대 프로세서가 탑재돼 성능이 빨라지는 게 가장 큰 특징이다. MS SQ1 프로세서의 향상된 버전인 SQ2 프로세서가 탑재돼 현존하는 ARM 기반의 PC 중 가장 빠른 성능을 선보인다고 회사 측은 설명했다. 전력 및 성능 향상으로 배터리 사용시간은 최대 15시간으로 길어졌다. 아이 컨택트(Eye Contact) 기능은 화상 통화를 할 때 서로 눈을 맞추면서 통화하는 느낌이 들도록 시선을 조정해줘서 커뮤니케이션을 돕는다. 시그니처 키보드는 플래티넘, 아이스 블루, 파피레드 등 세 가지 색상이 새로 출시된다. 서피스 프로 X 업데이트 버전의 국내 출시 일정과 가격은 조만간 발표된다. MS는 디자이너 콤팩트 키보드, 무선 블루투스 숫자 패드, 4K 무선 디스플레이 어댑터, 블루투스 인체공학 마우스 등 서피스 제품군을 위한 새로운 액세서리도 출시한다고 덧붙였다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 마이크로소프트, 신형 노트북 '서피스 랩탑 고' 출시 발표"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 13, 107, 12, 9, 54, 25, 28, 2055, 30, 1724, 5, 1050, 24, 32, 17, 76, 44, 7]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[속보] \"코로나19로 인한 소비...수도권서 2명 추가 확진\"'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize(\"'상온노출' 의심 인플루엔자(독감)백신 접종자가 연일 급증하고 있다. 당초 보건당국은 '문제의 백신 물량을 맞은 사람이 없다'고 발표했으나 접종자수가 어제 하루에만 548명이 늘어나 2000명에 육박하고 있는 것이다. 또한 예방접종치짐을 위반한 접종사례도 1479명분에 이른다. 이로인해 보건당국의 발표가 무색할 정도로 접종자가 늘어나면서 예방접종사업 전반에 걸쳐 부실관리에 대한 지적이 나오고 있다. 한편 질병청은 접종자 가운데 '이상 반응'을 신고한 사람이 이날 4명 더 늘어 총 8명이라고 밝혔다. 이상 반응을 새로 신고한 4명 가운데 2명은 오한·두통·메스꺼움 등, 1명은 두드러기, 1명은 설사 증상이 있다고 각각 보고했다. 질병청은 이와 관련해 '접종 이후 증상이 있었으나 호전된 상태'라고 설명했다. 앞서 이상 반응이 있다고 보고된 4명 역시 발열, 오한 등의 증상이 있었으나 호전됐다고 질병청은 전했다. 질병관리청은 1일 '인플루엔자 예방접종사업 관련' 참고자료를 내고 '현재 상온 노출 여부를 조사 중인 정부조달 (백신) 물량을 접종한 건수는 어제(9월 30일) 기준으로 총 1910건(명)'이라고 밝혔다. 질병청이 전날 발표한 1362명에 비해 하루 새 548명 늘어난 것이다. 접종이 이뤄진 날짜별로 보면 9월 21일까지 접종받은 사람이 1261명으로 가장 많았다. 이후 22일 431명, 23일 23명, 24일 22명, 25일 96명, 26일 38명, 27일 18명, 28일 21명 등이다. 질병청이 긴급하게 사용 중단 결정을 내리면서 일선 현장에서 혼선이 빚어질 수 있었다고 판단한 22일 당일을 제외한 전후의 접종 사례 1479명분의 물량은 모두 예방접종 지침을 위반한 것이다. 실제 한 의료기관에서는 돈을 내고 접종을 받은 60명이 정부의 무료 물량으로 무더기로 접종받은 사실이 드러났다. 질병청 관계자는 '(무료 접종) 사업 시작 전(22일 이전)과 중단 고지일 이후(23일 이후)에 접종이 이뤄진 사례는 국가 인플루엔자 예방접종 사업 지침을 미준수한 사례'라고 지적했다. 이어 '사업 중단 당일인 22일에 이뤄진 접종 사례는 사업 중단을 인지하지 못하고 접종한 것으로 보고 있다'며 '각 지방자치단체를 통해 사용 중지된 물량을 사용한 사례를 지속해서 조사하고 있다'고 설명했다. 접종자가 나온 지역은 강원과 울산을 제외한 전국 15개 시도다. 지역별로는 경기 673건, 전북 326건, 인천 214건, 경북 161건, 서울 149건, 부산 109건, 충남 74건, 세종 51건, 대구 46건, 광주 40건, 전남 31건, 대전 17건, 경남 10건, 제주 8건, 충북 1건 등이다. ◇ 전국 231곳 의료기관서 접종…이상반응 신고 4명 늘어 총 8명 '국가 인플루엔자 예방접종 사업 중단'이라는 초유의 사태 속에서 그간 일선 의료현장에서 백신 접종 및 관리를 부실하게 해 온 점도 조사 과정에서 속속 드러나고 있다. 통상 각 의료기관이 자체적으로 구비한 유료 접종 물량과 정부가 제공하는 무료 접종 물량은 별도로 관리해야 하지만 이를 섞어서 관리하거나 돈을 받고 정부 조달 물량을 쓰는 경우도 적지 않은 것으로 보인다. 현재까지 상온 노출이 의심돼 조사 중인 백신으로 접종한 병·의원만 하더라도 전국 231곳에 달한다. 지역별로 보면 경기가 93곳으로 가장 많고 이어 전북 31곳, 대구 22곳, 서울 18곳, 경북 15곳 부산·충남 11곳 등이다. 질병청은 앞서 국가 조달 물량을 공급하는 업체인 '신성약품'이 백신을 배송하는 과정에서 냉장차 문을 열어놓거나 제품을 바닥에 내려놓는 등 '냉장유통'(콜드체인) 원칙을 지키지 않은 사실을 확인하고 지난 21일 밤 사업 중단 방침을 전격 발표했다. 상온 노출이 의심돼 사용이 중단된 백신 물량은 총 578만명분이다. 당초 질병청은 백신 사용 중단을 발표한 직후인 지난달 22일 문제의 백신 접종자가 1명도 없다고 밝혔으나 9월 25일 이후부터 105명→224명→324명→407명→873명→1362명→1910명 등으로 연일 불어나고 있다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `상온 노출` 의심 독감백신 접종 전국 231곳서 2000명 육박"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://news.naver.com/main/read.nhn?mode=LSD&mid=shm&sid1=102&oid=081&aid=0003141547"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1748,
     "status": "ok",
     "timestamp": 1589005779180,
     "user": {
      "displayName": "rohan jagtap",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjFFnpJjw-7WaiTzz7xrkIJjBBwMs5i3OwVVYALIg=s64",
      "userId": "07173842849534370372"
     },
     "user_tz": -330
    },
    "id": "WZoEHvIxrYKZ",
    "outputId": "64212034-ffda-41f2-c830-fc1f17c674e6",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 20, 25, 4354, 343, 140, 5, 3577, 4, 8, 6779, 151, 6, 53, 315]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"코로나19 중증 환자 증가...국토부, '제로인'으로 결정\""
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize(\n",
    "    '대한감염학회 등 전문가 단체가 국내 코로나19 유행 상황에 대해 거리두기 단계 상향 등 강력한 방역 조치가 없으면 향후 1~2주 안에 하루 1000명에 육박하는 신규 확진자가 발생할 것이라고 경고했다.\\\n",
    "    대한감염학회 등은 20일 성명서를 통해 “현재 코로나19 상황은 더 악화할 가능성이 높다”며 이같이 밝혔다.\\\n",
    "    이들 학회는 “코로나19 바이러스는 낮은 온도, 건조한 환경에서 더 오래 생존하므로 현재 전파 위험이 높아진 상태”라며 “일일 감염재생산 지수가 1.5를 넘어선 상태여서 효과적 조치 없이 1∼2주 경과하면 일일 확진자 수가 1000명에 육박할 것으로 예측된다”고 밝혔다.\\\n",
    "    이들 학회는 “고위험군에 피해가 발생할 위험이 커지고 있고, 코로나19 중환자를 치료할 자원이 빠르게 고갈되고 있다”며 “발병 후 7∼10일쯤 중증으로 악화하는 코로나19 특성을 고려하면 중환자 병상은 1∼2주 내 빠르게 소진될 것”이라고 진단했다. 이에 따라 조기에 선제적으로 강력하게 방역 조치를 해야 한다고 주문했다.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 감염학회 “거리두기 상향 없으면 하루 확진자 1천명 육박할 것”\n",
    "\n",
    "\"코로나19 확산 속 '코로나19' 확산...코로나19 확산 우려\"\n",
    "\n",
    "'[속보] \"코로나19 백신, 방역 강화 위험 없어\"'\n",
    "'코로나19로 확진자 100만명 넘어...국내 발생 60세 이상'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://news.naver.com/main/read.nhn?mode=LSD&mid=shm&sid1=102&oid=025&aid=0003054205"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kNVOWPXFIn0k"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 223, 4, 8, 871, 2574, 6, 16, 32, 17, 70]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"경찰, '디지털 교도소'에 2명 사망\""
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize('서울 양천구의 한 인도에서 지나가던 행인을 무차별 폭행한 40대 남성 A씨가 20일 경찰에 붙잡혔다.\\\n",
    "서울 양천경찰서에 따르면, A씨는 지난 18일 오후 9시쯤 지하철 5호선 오목교역 근처에서 길을 가던 최모(42)씨와 어깨를 부딪치자 주먹을 휘두르고 발길질을 하며 수차례 폭행한 혐의를 받고 있다.\\\n",
    "신고를 받은 경찰이 출동했을 땐 A씨는 이미 현장에서 달아난 상태였다. 최씨는 당시 폭행으로 코뼈가 부러지고 뇌출혈 증상이 나타난 것으로 확인됐다.\\\n",
    "경찰은 주변 CCTV 등을 통해 A씨의 신원을 특정해 이틀 만에 덜미를 잡았다. 경찰 관계자는 “당시 A씨가 술에 취했던 것으로 추정된다”며 상해 등 혐의로 A씨를 입건했다.\\\n",
    "곧 A씨를 소환해 구체적인 범행 경위를 파악할 예정”이라고 말했다.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 경찰, 퇴근길 어깨 부딪히자 무차별 폭행한 40대 남성 입건\n",
    "\n",
    "\"[속보] 경찰, '코로나19'에 '묻지마 폭행' 50대 남성 구속영장 기각\"\n",
    "\n",
    "\"[속보] '음주운전' 차량 2명 사망...경찰 수사\"\n",
    "\n",
    "\"'나는 자연인이다' 심마니, 동료와 함께 숨져\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://news.naver.com/main/read.nhn?mode=LSD&mid=shm&sid1=102&oid=001&aid=0012030367"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 20, 25, 28, 2055, 30, 407, 4, 10, 30595, 211, 53, 1025, 8, 54, 25, 6, 251]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"코로나19로 인한 경기, 방문판매원으로 만든 '코로나19' 확산\""
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize(\"내 신종 코로나바이러스 감염증(코로나19) 확산세가 연일 거세지면서 21일 신규 확진자 수는 300명대 후반을 기록했다.\\\n",
    "전날(363명)보다 다소 늘어나면서 나흘 연속 300명대를 이어갔다.\\\n",
    "이는 수도권 중심의 '2차 유행'이 한창이던 8월 말 수준과 비슷한 상황이다. 당시엔 2차 유행의 정점을 찍었던 8월 27일(441명)을 전후로 4일 연속(320명→441명→371명→323명) 300명 이상이 단 1차례 있었다.\\\n",
    "그만큼 코로나19 상황이 심각하다는 방증으로, 정부도 지난 2∼3월 대구·경북 중심의 '1차 대유행'과 8월 2차 유행에 이어 '3차 유행'이 진행 중이라고 공식 확인한 상태다.\\\n",
    "이 같은 증가세는 기존 감염 사례에서 매일같이 확진자가 나오는 데다 학교나 학원, 종교시설, 각종 소모임 등을 고리로 전국 곳곳에서 크고 작은 집단발병이 연일 새로 발생하는 데 따른 것이다.\\\n",
    "정부는 환자 발생 동향을 주시하면서 수도권 등에 대한 '사회적 거리두기' 2단계 격상까지 열어두고 다각도의 대책을 모색하고 있다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 신규확진 386명 나흘연속 300명대, 지역 361명…3차 유행 본격화\n",
    "\n",
    "'[날씨] 전국 요란한 비...수도권 선선한 바람'\n",
    "\n",
    "'코로나19 신규 확진 69명...지역발생 50명'\n",
    "\n",
    "'[속보] 코로나19 신규 확진자 69명...사흘째 세자릿수'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'[속보] 신규확진 156명...엿새째 100명대 유지'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)\n",
    "scores = scorer.score(test,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': Score(precision=1.0, recall=1.0, fmeasure=1.0),\n",
       " 'rougeL': Score(precision=1.0, recall=1.0, fmeasure=1.0)}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = scorer.score(test,b)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \"코로나19로 인한 경기, 방문판매원으로 만든 '코로나19' 확산\"\n",
    "b = \"신규확진 386명 나흘연속 300명대, 지역 361명…3차 유행 본격화\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyN7AJp0I1extht6swPTmZxm",
   "collapsed_sections": [],
   "mount_file_id": "1P1vi4p4uje5OlCp9bdNqlbdxqUCX-qPJ",
   "name": "summarizer.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
