{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1916,
     "status": "ok",
     "timestamp": 1588996034233,
     "user": {
      "displayName": "rohan jagtap",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjFFnpJjw-7WaiTzz7xrkIJjBBwMs5i3OwVVYALIg=s64",
      "userId": "07173842849534370372"
     },
     "user_tz": -330
    },
    "id": "ImPCIsrTE5sF",
    "outputId": "08d02672-f289-4d78-c8c6-28bb35ca440f"
   },
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "%config InlineBackend.figure_format = 'retina'\n",
    " \n",
    "import matplotlib.font_manager as fm\n",
    "fontpath = '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf'\n",
    "font = fm.FontProperties(fname=fontpath, size=9)\n",
    "plt.rc('font', family='NanumBarunGothic') \n",
    "mpl.font_manager._rebuild()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zbxhyl_zFlWL"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "import os\n",
    "import io\n",
    "import time\n",
    "import random\n",
    "\n",
    "import seaborn # Attention 시각화를 위해 필요!\n",
    "from sklearn.model_selection import train_test_split\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yH5cg5pSIHaZ"
   },
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K_AjGkWXITKA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(83214, 7)\n"
     ]
    }
   ],
   "source": [
    "path1 = os.getenv('HOME') + '/aiffel/Deep_Sum/102/20201021-20201031' # 자신에 맞는 숫자 집어넣기\n",
    "path2 = os.getenv('HOME') + '/aiffel/Deep_Sum/102/20201011-20201020' # path\n",
    "path3 = os.getenv('HOME') + '/aiffel/Deep_Sum/102/20201001-20201010' # path\n",
    "filenames1 = glob.glob(path1 + \"/*.csv\") \n",
    "filenames2 = glob.glob(path2 + '/*.csv')\n",
    "filenames3 = glob.glob(path3 + '/*.csv')\n",
    "\n",
    "dfs = []\n",
    "for filename in filenames1:\n",
    "    dfs.append(pd.read_csv(filename))\n",
    "    \n",
    "#for filename in filenames2:\n",
    "#    dfs.append(pd.read_csv(filename))\n",
    "\n",
    "#for filename in filenames3:\n",
    "#    dfs.append(pd.read_csv(filename))\n",
    "\n",
    "\n",
    "data = pd.concat(dfs, ignore_index=True)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S-rYZhayIe9x"
   },
   "outputs": [],
   "source": [
    "data = data.drop_duplicates(['contents'], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 15455,
     "status": "ok",
     "timestamp": 1588996050470,
     "user": {
      "displayName": "rohan jagtap",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjFFnpJjw-7WaiTzz7xrkIJjBBwMs5i3OwVVYALIg=s64",
      "userId": "07173842849534370372"
     },
     "user_tz": -330
    },
    "id": "oXtxc-toIc94",
    "outputId": "d39eac33-f967-492d-e6f7-a2331bb638c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    오늘(30일) 밤 8시 40분쯤, 경기도 화성시 우정읍 우정읍사무소 인근 왕복 2차...\n",
      "1    기사 섹션 분류 안내\\n\\n기사의 섹션 정보는 해당 언론사의 분류를 따르고 있습니다...\n",
      "2    [한국경제TV 조시형 기자]\\n\\n전북 군산 만경강에서 지난 26일 채취한 야생조류...\n",
      "3    서울 송파구 서울동부지검. 2019.4.1/뉴스1 © News1 구윤성 기자 서울 ...\n",
      "4    동영상 뉴스\\n\\n[앵커]핼러윈을 맞아 서울 이태원 등 번화가에는 젊은이들의 발길이...\n",
      "Name: contents, dtype: object\n",
      "0              화성시 도로서 경차-트럭-트랙터 부딪혀…“2명 부상”\n",
      "1                             '홍대거리 방역조치 점검'\n",
      "2    군산 만경강 야생조류 분변서 AI 항원 검출…\"고병원성 여부 확인 중\"\n",
      "3           검찰, '소윤' 윤대진 친형 '변호사법 위반' 참고인 조사\n",
      "4                  핼러윈 맞은 이태원 밤은...'기대 속 긴장'\n",
      "Name: title, dtype: object\n",
      "60260\n"
     ]
    }
   ],
   "source": [
    "document = data['contents']\n",
    "summary = data['title']\n",
    "print(document.head())\n",
    "print(summary.head())\n",
    "print(len(document))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f8gKyq1gIq4r"
   },
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12201,
     "status": "ok",
     "timestamp": 1588996050475,
     "user": {
      "displayName": "rohan jagtap",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjFFnpJjw-7WaiTzz7xrkIJjBBwMs5i3OwVVYALIg=s64",
      "userId": "07173842849534370372"
     },
     "user_tz": -330
    },
    "id": "TJ6LE4MrJjC_",
    "outputId": "cb4f9812-a59f-4bfc-9111-e95c6c72c5f6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            <go> 화성시 도로서 경차-트럭-트랙터 부딪혀…“2명 부상” <stop>\n",
       "1                           <go> '홍대거리 방역조치 점검' <stop>\n",
       "2    <go> 군산 만경강 야생조류 분변서 AI 항원 검출…\"고병원성 여부 확인 중\" <...\n",
       "3         <go> 검찰, '소윤' 윤대진 친형 '변호사법 위반' 참고인 조사 <stop>\n",
       "4                <go> 핼러윈 맞은 이태원 밤은...'기대 속 긴장' <stop>\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for decoder sequence\n",
    "summary = summary.apply(lambda x: '<go> ' + x + ' <stop>')\n",
    "summary.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "95Zv7FIvKbTi"
   },
   "source": [
    "#### Tokenizing the texts into integer tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7TqbpEyPMRqa"
   },
   "outputs": [],
   "source": [
    "# since < and > from default tokens cannot be removed\n",
    "filters = '!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n'\n",
    "oov_token = '<unk>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cHw2csoYImsa"
   },
   "outputs": [],
   "source": [
    "document_tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words = 200000,oov_token=oov_token)\n",
    "summary_tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words = 200000, filters=filters, oov_token=oov_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DWU9Xu7OKVab"
   },
   "outputs": [],
   "source": [
    "document_tokenizer.fit_on_texts(document)\n",
    "summary_tokenizer.fit_on_texts(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3ESm-aYR-tvx"
   },
   "outputs": [],
   "source": [
    "inputs = document_tokenizer.texts_to_sequences(document)\n",
    "targets = summary_tokenizer.texts_to_sequences(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1240,
     "status": "ok",
     "timestamp": 1588996264681,
     "user": {
      "displayName": "rohan jagtap",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjFFnpJjw-7WaiTzz7xrkIJjBBwMs5i3OwVVYALIg=s64",
      "userId": "07173842849534370372"
     },
     "user_tz": -330
    },
    "id": "kVyErXAei5_b",
    "outputId": "41027c54-ce96-46d2-85c1-ff09bfe5d7dd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2019, 1]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_tokenizer.texts_to_sequences([\"월요일 발생했다.\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1268,
     "status": "ok",
     "timestamp": 1588996308592,
     "user": {
      "displayName": "rohan jagtap",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjFFnpJjw-7WaiTzz7xrkIJjBBwMs5i3OwVVYALIg=s64",
      "userId": "07173842849534370372"
     },
     "user_tz": -330
    },
    "id": "Ryx9qx90jwXu",
    "outputId": "c4b8270a-e497-47a5-e93b-90a328a7f0a9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['구축 검찰 확진자 대상']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_tokenizer.sequences_to_texts([[184, 22, 12, 71]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1311,
     "status": "ok",
     "timestamp": 1588996326633,
     "user": {
      "displayName": "rohan jagtap",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjFFnpJjw-7WaiTzz7xrkIJjBBwMs5i3OwVVYALIg=s64",
      "userId": "07173842849534370372"
     },
     "user_tz": -330
    },
    "id": "KoizyBvLKv8h",
    "outputId": "62198745-1a53-41ef-f10c-5c9ca315fbe4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(917272, 108308)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_vocab_size = len(document_tokenizer.word_index) + 1\n",
    "decoder_vocab_size = len(summary_tokenizer.word_index) + 1\n",
    "\n",
    "# vocab_size\n",
    "encoder_vocab_size, decoder_vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mZden_q9_eZr"
   },
   "source": [
    "#### Obtaining insights on lengths for defining maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ma4o2nGdK5Xb"
   },
   "outputs": [],
   "source": [
    "document_lengths = pd.Series([len(x) for x in document])\n",
    "summary_lengths = pd.Series([len(x) for x in summary])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1365,
     "status": "ok",
     "timestamp": 1588996333925,
     "user": {
      "displayName": "rohan jagtap",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjFFnpJjw-7WaiTzz7xrkIJjBBwMs5i3OwVVYALIg=s64",
      "userId": "07173842849534370372"
     },
     "user_tz": -330
    },
    "id": "iXZlO99C-UXK",
    "outputId": "8b1480e7-5481-43f0-b685-e1deecda4548"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    60260.000000\n",
       "mean       981.406356\n",
       "std       1170.912433\n",
       "min         57.000000\n",
       "25%        507.750000\n",
       "50%        801.000000\n",
       "75%       1165.000000\n",
       "max      40129.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_lengths.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1139,
     "status": "ok",
     "timestamp": 1588996333927,
     "user": {
      "displayName": "rohan jagtap",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjFFnpJjw-7WaiTzz7xrkIJjBBwMs5i3OwVVYALIg=s64",
      "userId": "07173842849534370372"
     },
     "user_tz": -330
    },
    "id": "ALMwKMx--ZF7",
    "outputId": "df49e521-f058-466e-ec7c-f667c215c748"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    60260.000000\n",
       "mean        41.899635\n",
       "std          6.847516\n",
       "min         16.000000\n",
       "25%         38.000000\n",
       "50%         42.000000\n",
       "75%         46.000000\n",
       "max        132.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_lengths.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cVeMilXr-bpC"
   },
   "outputs": [],
   "source": [
    "# maxlen\n",
    "# taking values > and round figured to 75th percentile\n",
    "# at the same time not leaving high variance\n",
    "encoder_maxlen = 400\n",
    "decoder_maxlen = 75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_SWap3YJBk-D"
   },
   "source": [
    "#### Padding/Truncating sequences for identical sequence lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vEyUBeu7ACRt"
   },
   "outputs": [],
   "source": [
    "inputs = tf.keras.preprocessing.sequence.pad_sequences(inputs, maxlen=encoder_maxlen, padding='post', truncating='post')\n",
    "targets = tf.keras.preprocessing.sequence.pad_sequences(targets, maxlen=decoder_maxlen, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wIP0kIIcB8Rm"
   },
   "source": [
    "### Creating dataset pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LzO6l3-AB7hJ"
   },
   "outputs": [],
   "source": [
    "inputs = tf.cast(inputs, dtype=tf.int32)\n",
    "targets = tf.cast(targets, dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60260, 400)\n",
      "(60260, 75)\n"
     ]
    }
   ],
   "source": [
    "print(inputs.shape)\n",
    "print(targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "slZ5f4P4DurS"
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 20000\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wI-fV7eABWN6"
   },
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((inputs, targets)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "isN1CpAXLfsl"
   },
   "source": [
    "### Positional Encoding for adding notion of position among words as unlike RNN this is non-directional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Purv7oyhETDZ"
   },
   "outputs": [],
   "source": [
    "def get_angles(position, i, d_model):\n",
    "    angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n",
    "    return position * angle_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "40J2pc2NEXp5"
   },
   "outputs": [],
   "source": [
    "def positional_encoding(position, d_model):\n",
    "    angle_rads = get_angles(\n",
    "        np.arange(position)[:, np.newaxis],\n",
    "        np.arange(d_model)[np.newaxis, :],\n",
    "        d_model\n",
    "    )\n",
    "\n",
    "    # apply sin to even indices in the array; 2i\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "\n",
    "    # apply cos to odd indices in the array; 2i+1\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "\n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "24Pe01DMMWHc"
   },
   "source": [
    "### Masking\n",
    "\n",
    "- Padding mask for masking \"pad\" sequences\n",
    "- Lookahead mask for masking future words from contributing in prediction of current words in self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hN1wVQAdMVYy"
   },
   "outputs": [],
   "source": [
    "def create_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UmjAPLWuMREE"
   },
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(size):\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n8DqUBc4NFOy"
   },
   "source": [
    "### Building the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WfknVF7hNKf7"
   },
   "source": [
    "#### Scaled Dot Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w_B6M9OBNBKB"
   },
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "    matmul_qk = tf.matmul(q, k, transpose_b=True)\n",
    "\n",
    "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "    if mask is not None:\n",
    "        scaled_attention_logits += (mask * -1e9)  \n",
    "\n",
    "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n",
    "\n",
    "    output = tf.matmul(attention_weights, v)\n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rf7_a5uQOfJk"
   },
   "source": [
    "#### Multi-Headed Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iIuFrdXnNZEC"
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.wq = tf.keras.layers.Dense(d_model)\n",
    "        self.wk = tf.keras.layers.Dense(d_model)\n",
    "        self.wv = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "    def split_heads(self, x, batch_size):\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "    \n",
    "    def call(self, v, k, q, mask):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "\n",
    "        q = self.wq(q)\n",
    "        k = self.wk(k)\n",
    "        v = self.wv(v)\n",
    "\n",
    "        q = self.split_heads(q, batch_size)\n",
    "        k = self.split_heads(k, batch_size)\n",
    "        v = self.split_heads(v, batch_size)\n",
    "\n",
    "        scaled_attention, attention_weights = scaled_dot_product_attention(\n",
    "            q, k, v, mask)\n",
    "\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))\n",
    "        output = self.dense(concat_attention)\n",
    "            \n",
    "        return output, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A49tXMVvOkOZ"
   },
   "source": [
    "### Feed Forward Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d9-qoKuTNwKq"
   },
   "outputs": [],
   "source": [
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(dff, activation='relu'),\n",
    "        tf.keras.layers.Dense(d_model)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B2RRmn2bOpW9"
   },
   "source": [
    "#### Fundamental Unit of Transformer encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HNuoJoFWO335"
   },
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "    def call(self, x, training, mask):\n",
    "        attn_output, _ = self.mha(x, x, x, mask)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(x + attn_output)\n",
    "\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        out2 = self.layernorm2(out1 + ffn_output)\n",
    "\n",
    "        return out2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9i6Zh8gnPqdW"
   },
   "source": [
    "#### Fundamental Unit of Transformer decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7CVmvs6dPMRC"
   },
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
    "        self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout3 = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "    \n",
    "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
    "        attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)\n",
    "        attn1 = self.dropout1(attn1, training=training)\n",
    "        out1 = self.layernorm1(attn1 + x)\n",
    "\n",
    "        attn2, attn_weights_block2 = self.mha2(enc_output, enc_output, out1, padding_mask)\n",
    "        attn2 = self.dropout2(attn2, training=training)\n",
    "        out2 = self.layernorm2(attn2 + out1)\n",
    "\n",
    "        ffn_output = self.ffn(out2)\n",
    "        ffn_output = self.dropout3(ffn_output, training=training)\n",
    "        out3 = self.layernorm3(ffn_output + out2)\n",
    "\n",
    "        return out3, attn_weights_block1, attn_weights_block2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6zt5MUc_QNid"
   },
   "source": [
    "#### Encoder consisting of multiple EncoderLayer(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BrbnTwijQJ-h"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, maximum_position_encoding, rate=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, self.d_model)\n",
    "\n",
    "        self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "        \n",
    "    def call(self, x, training, mask):\n",
    "        seq_len = tf.shape(x)[1]\n",
    "\n",
    "        x = self.embedding(x)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        x = self.dropout(x, training=training)\n",
    "    \n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x, training, mask)\n",
    "    \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4N5LrNrvRexg"
   },
   "source": [
    "#### Decoder consisting of multiple DecoderLayer(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UmeqkZrIRbSB"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size, maximum_position_encoding, rate=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
    "\n",
    "        self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        attention_weights = {}\n",
    "\n",
    "        x = self.embedding(x)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
    "\n",
    "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
    "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
    "    \n",
    "        return x, attention_weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lbMNK_bzSHnh"
   },
   "source": [
    "#### Finally, the Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FXHRG-o4R9Mc"
   },
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, target_vocab_size, pe_input, pe_target, rate=0.1):\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        self.encoder = Encoder(num_layers, d_model, num_heads, dff, input_vocab_size, pe_input, rate)\n",
    "\n",
    "        self.decoder = Decoder(num_layers, d_model, num_heads, dff, target_vocab_size, pe_target, rate)\n",
    "\n",
    "        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "    \n",
    "    def call(self, inp, tar, training, enc_padding_mask, look_ahead_mask, dec_padding_mask):\n",
    "        enc_output = self.encoder(inp, training, enc_padding_mask)\n",
    "\n",
    "        dec_output, attention_weights = self.decoder(tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
    "\n",
    "        final_output = self.final_layer(dec_output)\n",
    "\n",
    "        return final_output, attention_weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UndsMPZXTdSr"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lMTZJdIoSbuy"
   },
   "outputs": [],
   "source": [
    "# hyper-params\n",
    "num_layers = 4\n",
    "d_model = 128\n",
    "dff = 512\n",
    "num_heads = 8\n",
    "EPOCHS = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uOGvkYDNTjIj"
   },
   "source": [
    "#### Adam optimizer with custom learning rate scheduling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tfiynCLlTL8C"
   },
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "    \n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DsVdrENTUERY"
   },
   "source": [
    "#### Defining losses and other metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ip1-943kTXXK"
   },
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(d_model)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ktKwyvKtTvF6"
   },
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uW4LA_45T4Aa"
   },
   "outputs": [],
   "source": [
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ze0u6xxXT7dI"
   },
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9XvKy3v6ULnO"
   },
   "source": [
    "#### Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d5-RcxqFUCuk"
   },
   "outputs": [],
   "source": [
    "transformer = Transformer(\n",
    "    num_layers, \n",
    "    d_model, \n",
    "    num_heads, \n",
    "    dff,\n",
    "    encoder_vocab_size, \n",
    "    decoder_vocab_size, \n",
    "    pe_input=encoder_vocab_size, \n",
    "    pe_target=decoder_vocab_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f56BGiVXU_Dk"
   },
   "source": [
    "#### Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FZxHuyZxU5Pa"
   },
   "outputs": [],
   "source": [
    "def create_masks(inp, tar):\n",
    "    enc_padding_mask = create_padding_mask(inp)\n",
    "    dec_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "    dec_target_padding_mask = create_padding_mask(tar)\n",
    "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "  \n",
    "    return enc_padding_mask, combined_mask, dec_padding_mask\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SYIotvaBVI0d"
   },
   "source": [
    "#### Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7786,
     "status": "ok",
     "timestamp": 1588996357748,
     "user": {
      "displayName": "rohan jagtap",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjFFnpJjw-7WaiTzz7xrkIJjBBwMs5i3OwVVYALIg=s64",
      "userId": "07173842849534370372"
     },
     "user_tz": -330
    },
    "id": "tOc1_3c-VGaL",
    "outputId": "eeab15d7-f887-4f37-dfec-c980948f97d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest checkpoint restored!!\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = \"checkpoints\"\n",
    "\n",
    "ckpt = tf.train.Checkpoint(transformer=transformer, optimizer=optimizer)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    print ('Latest checkpoint restored!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WfpI0gS4c06c"
   },
   "source": [
    "#### Training steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xmVOMzkrczgl"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, tar):\n",
    "    tar_inp = tar[:, :-1]\n",
    "    tar_real = tar[:, 1:]\n",
    "\n",
    "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions, _ = transformer(\n",
    "            inp, tar_inp, \n",
    "            True, \n",
    "            enc_padding_mask, \n",
    "            combined_mask, \n",
    "            dec_padding_mask\n",
    "        )\n",
    "        loss = loss_function(tar_real, predictions)\n",
    "\n",
    "    gradients = tape.gradient(loss, transformer.trainable_variables)    \n",
    "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
    "\n",
    "    train_loss(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6000532,
     "status": "ok",
     "timestamp": 1589005387811,
     "user": {
      "displayName": "rohan jagtap",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjFFnpJjw-7WaiTzz7xrkIJjBBwMs5i3OwVVYALIg=s64",
      "userId": "07173842849534370372"
     },
     "user_tz": -330
    },
    "id": "xORKpv69dSW5",
    "outputId": "572d3232-3af4-4bd6-ebc7-a151f6ad000d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 3.7894\n",
      "Epoch 1 Batch 258 Loss 3.7831\n",
      "Epoch 1 Batch 516 Loss 3.8761\n",
      "Epoch 1 Batch 774 Loss 3.9980\n",
      "Epoch 1 Loss 4.1024\n",
      "Time taken for 1 epoch: 844.0596919059753 secs\n",
      "\n",
      "Epoch 2 Batch 0 Loss 3.7634\n",
      "Epoch 2 Batch 258 Loss 3.7773\n",
      "Epoch 2 Batch 516 Loss 3.8684\n",
      "Epoch 2 Batch 774 Loss 3.9731\n",
      "Epoch 2 Loss 4.0697\n",
      "Time taken for 1 epoch: 827.1838057041168 secs\n",
      "\n",
      "Epoch 3 Batch 0 Loss 3.7160\n",
      "Epoch 3 Batch 258 Loss 3.7345\n",
      "Epoch 3 Batch 516 Loss 3.8450\n",
      "Epoch 3 Batch 774 Loss 3.9472\n",
      "Epoch 3 Loss 4.0406\n",
      "Time taken for 1 epoch: 822.4597451686859 secs\n",
      "\n",
      "Epoch 4 Batch 0 Loss 4.0017\n",
      "Epoch 4 Batch 258 Loss 3.7006\n",
      "Epoch 4 Batch 516 Loss 3.7906\n",
      "Epoch 4 Batch 774 Loss 3.9193\n",
      "Epoch 4 Loss 4.0232\n",
      "Time taken for 1 epoch: 824.7425858974457 secs\n",
      "\n",
      "Epoch 5 Batch 0 Loss 3.7015\n",
      "Epoch 5 Batch 258 Loss 3.6761\n",
      "Epoch 5 Batch 516 Loss 3.7719\n",
      "Epoch 5 Batch 774 Loss 3.8896\n",
      "Saving checkpoint for epoch 5 at checkpoints/ckpt-9\n",
      "Epoch 5 Loss 3.9858\n",
      "Time taken for 1 epoch: 825.928300857544 secs\n",
      "\n",
      "Epoch 6 Batch 0 Loss 3.3902\n",
      "Epoch 6 Batch 258 Loss 3.6596\n",
      "Epoch 6 Batch 516 Loss 3.7542\n",
      "Epoch 6 Batch 774 Loss 3.8621\n",
      "Epoch 6 Loss 3.9634\n",
      "Time taken for 1 epoch: 820.1531503200531 secs\n",
      "\n",
      "Epoch 7 Batch 0 Loss 3.5910\n",
      "Epoch 7 Batch 258 Loss 3.6572\n",
      "Epoch 7 Batch 516 Loss 3.7348\n",
      "Epoch 7 Batch 774 Loss 3.8374\n",
      "Epoch 7 Loss 3.9437\n",
      "Time taken for 1 epoch: 824.052413225174 secs\n",
      "\n",
      "Epoch 8 Batch 0 Loss 3.6032\n",
      "Epoch 8 Batch 258 Loss 3.6310\n",
      "Epoch 8 Batch 516 Loss 3.7145\n",
      "Epoch 8 Batch 774 Loss 3.8284\n",
      "Epoch 8 Loss 3.9241\n",
      "Time taken for 1 epoch: 821.0618391036987 secs\n",
      "\n",
      "Epoch 9 Batch 0 Loss 3.2316\n",
      "Epoch 9 Batch 258 Loss 3.6021\n",
      "Epoch 9 Batch 516 Loss 3.7016\n",
      "Epoch 9 Batch 774 Loss 3.8082\n",
      "Epoch 9 Loss 3.9078\n",
      "Time taken for 1 epoch: 823.7007133960724 secs\n",
      "\n",
      "Epoch 10 Batch 0 Loss 3.1261\n",
      "Epoch 10 Batch 258 Loss 3.6065\n",
      "Epoch 10 Batch 516 Loss 3.6822\n",
      "Epoch 10 Batch 774 Loss 3.7863\n",
      "Saving checkpoint for epoch 10 at checkpoints/ckpt-10\n",
      "Epoch 10 Loss 3.8806\n",
      "Time taken for 1 epoch: 811.380380153656 secs\n",
      "\n",
      "Epoch 11 Batch 0 Loss 3.4890\n",
      "Epoch 11 Batch 258 Loss 3.5513\n",
      "Epoch 11 Batch 516 Loss 3.6568\n",
      "Epoch 11 Batch 774 Loss 3.7721\n",
      "Epoch 11 Loss 3.8710\n",
      "Time taken for 1 epoch: 785.921891450882 secs\n",
      "\n",
      "Epoch 12 Batch 0 Loss 3.5648\n",
      "Epoch 12 Batch 258 Loss 3.5678\n",
      "Epoch 12 Batch 516 Loss 3.6348\n",
      "Epoch 12 Batch 774 Loss 3.7510\n",
      "Epoch 12 Loss 3.8443\n",
      "Time taken for 1 epoch: 786.583869934082 secs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "\n",
    "    train_loss.reset_states()\n",
    "  \n",
    "    for (batch, (inp, tar)) in enumerate(dataset):\n",
    "        train_step(inp, tar)\n",
    "    \n",
    "        # 55k samples\n",
    "        # we display 3 batch results -- 0th, middle and last one (approx)\n",
    "        # 55k / 64 ~ 858; 858 / 2 = 429\n",
    "        if batch % 258 == 0:\n",
    "            print ('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1, batch, train_loss.result()))\n",
    "      \n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        ckpt_save_path = ckpt_manager.save()\n",
    "        print ('Saving checkpoint for epoch {} at {}'.format(epoch+1, ckpt_save_path))\n",
    "    \n",
    "    print ('Epoch {} Loss {:.4f}'.format(epoch + 1, train_loss.result()))\n",
    "\n",
    "    print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PVbEUCZagJ0G"
   },
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YMbqGTixu1cl"
   },
   "source": [
    "#### Predicting one word at a time at the decoder and appending it to the output; then taking the complete sequence as an input to the decoder and repeating until maxlen or stop keyword appears"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F5D5cv2Jd8-6"
   },
   "outputs": [],
   "source": [
    "def evaluate(input_document):\n",
    "    input_document = document_tokenizer.texts_to_sequences([input_document])\n",
    "    input_document = tf.keras.preprocessing.sequence.pad_sequences(input_document, maxlen=encoder_maxlen, padding='post', truncating='post')\n",
    "\n",
    "    encoder_input = tf.expand_dims(input_document[0], 0)\n",
    "\n",
    "    decoder_input = [summary_tokenizer.word_index[\"<go>\"]]\n",
    "    output = tf.expand_dims(decoder_input, 0)\n",
    "    \n",
    "    for i in range(decoder_maxlen):\n",
    "        enc_padding_mask, combined_mask, dec_padding_mask = create_masks(encoder_input, output)\n",
    "\n",
    "        predictions, attention_weights = transformer(\n",
    "            encoder_input, \n",
    "            output,\n",
    "            False,\n",
    "            enc_padding_mask,\n",
    "            combined_mask,\n",
    "            dec_padding_mask\n",
    "        )\n",
    "\n",
    "        predictions = predictions[: ,-1:, :]\n",
    "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "        if predicted_id == summary_tokenizer.word_index[\"<stop>\"]:\n",
    "            return tf.squeeze(output, axis=0), attention_weights\n",
    "\n",
    "        output = tf.concat([output, predicted_id], axis=-1)\n",
    "\n",
    "    return tf.squeeze(output, axis=0), attention_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UkpdiW6wnmiS"
   },
   "outputs": [],
   "source": [
    "def summarize(input_document):\n",
    "    # not considering attention weights for now, can be used to plot attention heatmaps in the future\n",
    "    summarized = evaluate(input_document=input_document)[0].numpy()\n",
    "    summarized = np.expand_dims(summarized[1:], 0)  # not printing <go> token\n",
    "    return summary_tokenizer.sequences_to_texts(summarized)[0]  # since there is just one translated document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://news.naver.com/main/read.nhn?mode=LSD&mid=shm&sid1=102&oid=081&aid=0003141547"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1748,
     "status": "ok",
     "timestamp": 1589005779180,
     "user": {
      "displayName": "rohan jagtap",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjFFnpJjw-7WaiTzz7xrkIJjBBwMs5i3OwVVYALIg=s64",
      "userId": "07173842849534370372"
     },
     "user_tz": -330
    },
    "id": "WZoEHvIxrYKZ",
    "outputId": "64212034-ffda-41f2-c830-fc1f17c674e6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'코로나19 피해 사상 최대 규모 조직 구성'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize(\n",
    "    '대한감염학회 등 전문가 단체가 국내 코로나19 유행 상황에 대해 거리두기 단계 상향 등 강력한 방역 조치가 없으면 향후 1~2주 안에 하루 1000명에 육박하는 신규 확진자가 발생할 것이라고 경고했다.\\\n",
    "    대한감염학회 등은 20일 성명서를 통해 “현재 코로나19 상황은 더 악화할 가능성이 높다”며 이같이 밝혔다.\\\n",
    "    이들 학회는 “코로나19 바이러스는 낮은 온도, 건조한 환경에서 더 오래 생존하므로 현재 전파 위험이 높아진 상태”라며 “일일 감염재생산 지수가 1.5를 넘어선 상태여서 효과적 조치 없이 1∼2주 경과하면 일일 확진자 수가 1000명에 육박할 것으로 예측된다”고 밝혔다.\\\n",
    "    이들 학회는 “고위험군에 피해가 발생할 위험이 커지고 있고, 코로나19 중환자를 치료할 자원이 빠르게 고갈되고 있다”며 “발병 후 7∼10일쯤 중증으로 악화하는 코로나19 특성을 고려하면 중환자 병상은 1∼2주 내 빠르게 소진될 것”이라고 진단했다. 이에 따라 조기에 선제적으로 강력하게 방역 조치를 해야 한다고 주문했다.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://news.naver.com/main/read.nhn?mode=LSD&mid=shm&sid1=102&oid=025&aid=0003054205"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kNVOWPXFIn0k"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'마스크 착용 안 해 승차 정비 1심서 폭행'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize('서울 양천구의 한 인도에서 지나가던 행인을 무차별 폭행한 40대 남성 A씨가 20일 경찰에 붙잡혔다.\\\n",
    "서울 양천경찰서에 따르면, A씨는 지난 18일 오후 9시쯤 지하철 5호선 오목교역 근처에서 길을 가던 최모(42)씨와 어깨를 부딪치자 주먹을 휘두르고 발길질을 하며 수차례 폭행한 혐의를 받고 있다.\\\n",
    "신고를 받은 경찰이 출동했을 땐 A씨는 이미 현장에서 달아난 상태였다. 최씨는 당시 폭행으로 코뼈가 부러지고 뇌출혈 증상이 나타난 것으로 확인됐다.\\\n",
    "경찰은 주변 CCTV 등을 통해 A씨의 신원을 특정해 이틀 만에 덜미를 잡았다. 경찰 관계자는 “당시 A씨가 술에 취했던 것으로 추정된다”며 상해 등 혐의로 A씨를 입건했다.\\\n",
    "곧 A씨를 소환해 구체적인 범행 경위를 파악할 예정”이라고 말했다.'\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://news.naver.com/main/read.nhn?mode=LSD&mid=shm&sid1=102&oid=001&aid=0012030367"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'코로나19 중앙방역대책본부 브리핑'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize(\"내 신종 코로나바이러스 감염증(코로나19) 확산세가 연일 거세지면서 21일 신규 확진자 수는 300명대 후반을 기록했다.\\\n",
    "전날(363명)보다 다소 늘어나면서 나흘 연속 300명대를 이어갔다.\\\n",
    "이는 수도권 중심의 '2차 유행'이 한창이던 8월 말 수준과 비슷한 상황이다. 당시엔 2차 유행의 정점을 찍었던 8월 27일(441명)을 전후로 4일 연속(320명→441명→371명→323명) 300명 이상이 단 1차례 있었다.\\\n",
    "그만큼 코로나19 상황이 심각하다는 방증으로, 정부도 지난 2∼3월 대구·경북 중심의 '1차 대유행'과 8월 2차 유행에 이어 '3차 유행'이 진행 중이라고 공식 확인한 상태다.\\\n",
    "이 같은 증가세는 기존 감염 사례에서 매일같이 확진자가 나오는 데다 학교나 학원, 종교시설, 각종 소모임 등을 고리로 전국 곳곳에서 크고 작은 집단발병이 연일 새로 발생하는 데 따른 것이다.\\\n",
    "정부는 환자 발생 동향을 주시하면서 수도권 등에 대한 '사회적 거리두기' 2단계 격상까지 열어두고 다각도의 대책을 모색하고 있다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'코로나19 어제 확진 사흘째 세자리 지역 93명 해외 더 낮아'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize(\"중앙방역대책본부는 이날 0시 기준으로 코로나19 신규 확진자가 386명 늘어 누적3만403명이라고 밝혔다.\\\n",
    "전날(363명)과 비교하면 23명 늘었다.\\\n",
    "신규 확진자 386명은 8월 27일(441명) 이후 86일 만에 최다 기록이다.\\\n",
    "이달 들어 일별 신규 확진자 수는 124명→97명→75명→118명→125명→145명→89명→143명→126명→100명→146명→143명→191명→205명→208명→222명→230명→313명→343명→363명→386명 등이다. 지난 8일부터 2주 연속 세 자릿수를 이어간 가운데 300명대만 4차례다.\\\n",
    "이날 신규 확진자 386명의 감염경로를 보면 지역발생이 361명, 해외유입이 25명이다.\\\n",
    "지역발생 확진자는 지난 11일(113명) 이후 11일 연속 세 자릿수를 기록했으며, 수치상으로는 2차 유행의 정점이었던 8월 27일(434명) 이후 가장 많다.\\\n",
    "확진자가 나온 지역을 보면 서울 154명, 경기 86명, 인천 22명 등 수도권이 262명이다. 전날(218명)보다 44명 늘었다. 수도권 확진자가 연이틀 200명대를 기록한 것도 8월 29∼30일(244명→203명) 이후 처음이다.\\\n",
    "수도권 외 지역은 충남 19명, 전남 18명, 강원 14명, 전북 13명, 경남 11명, 경북 8명, 부산 7명, 광주 6명, 대전·울산·충북 각 1명이다. 비수도권 지역발생 확진자는 전날(102명)보다 3명 줄어든 99명으로, 100명에 육박했다.\\\n",
    "주요 감염 사례를 보면 수도권의 경우 전날 낮 12시까지 서울 동작구 노량진의 대형 교원 임용고시학원(누적 32명), 서대문구 연세대학교 학생모임(19명), 동대문구 고등학교(9명), 도봉구 종교시설 '청련사'(29명), 경기 안산시 수영장(17명), 인천 남동구 가족 및 지인(40명) 사례를 중심으로 확진자가 대거 나왔다.\\\n",
    "비수도권 지역에서는 충남 아산시 선문대학교(14명), 경남 창원시 친목모임(23명), 경남 하동군 중학교(26명), 전북 익산시 원광대병원(11명), 강원 철원군 장애인 요양원(40명), 광주 전남대병원(46명) 등 다양한 감염 고리를 통해 확진자가 잇따랐다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyN7AJp0I1extht6swPTmZxm",
   "collapsed_sections": [],
   "mount_file_id": "1P1vi4p4uje5OlCp9bdNqlbdxqUCX-qPJ",
   "name": "summarizer.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
